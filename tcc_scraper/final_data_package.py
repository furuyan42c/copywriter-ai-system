import json
import csv
import os
from datetime import datetime
import shutil

def create_final_data_package():
    """æœ€çµ‚çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½œæˆ"""
    print("ğŸ“¦ TCC ãƒ‡ãƒ¼ã‚¿ æœ€çµ‚ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆ")
    print("=" * 50)
    
    # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    package_dir = f"TCC_DATA_PACKAGE_{timestamp}"
    os.makedirs(package_dir, exist_ok=True)
    
    # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    subdirs = ['basic_data', 'detailed_data', 'analysis', 'scripts']
    for subdir in subdirs:
        os.makedirs(os.path.join(package_dir, subdir), exist_ok=True)
    
    print(f"ğŸ“ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {package_dir}")
    
    # 1. åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
    print("\nğŸ“‹ åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸...")
    basic_files = [
        'tcc_data_100items_20250816_004700.json',
        'tcc_analysis_20250816_004700.json',
        'tcc_export_20250816_005024.csv',
        'tcc_export_20250816_005024_pretty.json'
    ]
    
    for file in basic_files:
        if os.path.exists(file):
            shutil.copy2(file, os.path.join(package_dir, 'basic_data'))
            print(f"  âœ… {file}")
        else:
            print(f"  âš ï¸ {file} (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
    
    # 2. è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
    print("\nğŸ“Š è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸...")
    detailed_files = [
        'tcc_enhanced_20250816_005213.json',
        'tcc_detailed_20250816_005213.csv',
        'tcc_detailed_analysis_20250816_005213.txt'
    ]
    
    for file in detailed_files:
        if os.path.exists(file):
            shutil.copy2(file, os.path.join(package_dir, 'detailed_data'))
            print(f"  âœ… {file}")
        else:
            print(f"  âš ï¸ {file} (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
    
    # 3. åˆ†æãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
    print("\nğŸ“ˆ åˆ†æãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸...")
    analysis_files = [
        'tcc_export_20250816_005024_detailed.txt',
        'tcc_export_20250816_005024_copywriters.csv',
        'tcc_summary_report_20250816_004700.md'
    ]
    
    for file in analysis_files:
        if os.path.exists(file):
            shutil.copy2(file, os.path.join(package_dir, 'analysis'))
            print(f"  âœ… {file}")
        else:
            print(f"  âš ï¸ {file} (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
    
    # 4. ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
    print("\nğŸ”§ ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸...")
    script_files = [
        'tcc_table_scraper.py',
        'detail_scraper.py',
        'full_crawler.py',
        'simple_export.py'
    ]
    
    for file in script_files:
        if os.path.exists(file):
            shutil.copy2(file, os.path.join(package_dir, 'scripts'))
            print(f"  âœ… {file}")
        else:
            print(f"  âš ï¸ {file} (è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
    
    # 5. READMEãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    readme_content = create_readme_content()
    readme_file = os.path.join(package_dir, 'README.md')
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    print(f"\nğŸ“ README.md ã‚’ä½œæˆ: {readme_file}")
    
    # 6. ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
    summary_content = create_data_summary()
    summary_file = os.path.join(package_dir, 'DATA_SUMMARY.txt')
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(summary_content)
    print(f"ğŸ“Š DATA_SUMMARY.txt ã‚’ä½œæˆ: {summary_file}")
    
    # 7. ä½¿ç”¨æ–¹æ³•ã‚¬ã‚¤ãƒ‰ã‚’ä½œæˆ
    guide_content = create_usage_guide()
    guide_file = os.path.join(package_dir, 'USAGE_GUIDE.md')
    with open(guide_file, 'w', encoding='utf-8') as f:
        f.write(guide_content)
    print(f"ğŸ“– USAGE_GUIDE.md ã‚’ä½œæˆ: {guide_file}")
    
    # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
    total_size = 0
    file_count = 0
    for root, dirs, files in os.walk(package_dir):
        for file in files:
            file_path = os.path.join(root, file)
            total_size += os.path.getsize(file_path)
            file_count += 1
    
    print(f"\nğŸ‰ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆå®Œäº†!")
    print("=" * 50)
    print(f"ğŸ“ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {package_dir}")
    print(f"ğŸ“Š ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {file_count}")
    print(f"ğŸ’¾ ç·ã‚µã‚¤ã‚º: {total_size:,} bytes ({total_size/1024/1024:.2f} MB)")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’è¡¨ç¤º
    print(f"\nğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :")
    for root, dirs, files in os.walk(package_dir):
        level = root.replace(package_dir, '').count(os.sep)
        indent = ' ' * 2 * level
        print(f"{indent}{os.path.basename(root)}/")
        subindent = ' ' * 2 * (level + 1)
        for file in files:
            print(f"{subindent}{file}")
    
    return package_dir

def create_readme_content():
    """READMEãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ä½œæˆ"""
    content = f"""# TCC ã‚³ãƒ”ãƒ© ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸

ä½œæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

## ğŸ“‹ æ¦‚è¦

ã“ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«ã¯ã€æ±äº¬ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã‚ºã‚¯ãƒ©ãƒ–ï¼ˆTCCï¼‰ã®ã‚³ãƒ”ãƒ©ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã—ãŸåºƒå‘Šãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
TCC_DATA_PACKAGE/
â”œâ”€â”€ basic_data/          # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ï¼ˆ100ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«ï¼‰
â”œâ”€â”€ detailed_data/       # è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆè©³ç´°ãƒšãƒ¼ã‚¸æƒ…å ±ä»˜ãï¼‰
â”œâ”€â”€ analysis/            # åˆ†æçµæœã¨ãƒ¬ãƒãƒ¼ãƒˆ
â”œâ”€â”€ scripts/             # ãƒ‡ãƒ¼ã‚¿å–å¾—ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ README.md            # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ DATA_SUMMARY.txt     # ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦
â””â”€â”€ USAGE_GUIDE.md       # ä½¿ç”¨æ–¹æ³•ã‚¬ã‚¤ãƒ‰
```

## ğŸ¯ ãƒ‡ãƒ¼ã‚¿ã®ç¨®é¡

### åŸºæœ¬ãƒ‡ãƒ¼ã‚¿
- **tcc_data_100items_*.json**: ä¸€è¦§ãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—ã—ãŸåŸºæœ¬æƒ…å ±ï¼ˆ100ä»¶ï¼‰
- **tcc_export_*.csv**: CSVå½¢å¼ã®åŸºæœ¬ãƒ‡ãƒ¼ã‚¿
- **tcc_analysis_*.json**: åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã®åˆ†æçµæœ

### è©³ç´°ãƒ‡ãƒ¼ã‚¿
- **tcc_enhanced_*.json**: è©³ç´°ãƒšãƒ¼ã‚¸æƒ…å ±ã‚’å«ã‚€æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ï¼ˆ20ä»¶ï¼‰
- **tcc_detailed_*.csv**: è©³ç´°æƒ…å ±ã‚’å«ã‚€CSV
- **tcc_detailed_analysis_*.txt**: è©³ç´°ãƒ‡ãƒ¼ã‚¿ã®åˆ†æçµæœ

### åˆ†æçµæœ
- **tcc_summary_report_*.md**: å…¨ä½“ã®ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
- **tcc_copywriters.csv**: ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼åˆ¥é›†è¨ˆ
- **tcc_detailed.txt**: è©³ç´°ãªçµ±è¨ˆæƒ…å ±

## ğŸ”§ åˆ©ç”¨å¯èƒ½ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### tcc_table_scraper.py
- ä¸€è¦§ãƒšãƒ¼ã‚¸ã‹ã‚‰åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
- æŒ‡å®šä»¶æ•°åˆ†ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’åé›†

### detail_scraper.py
- è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
- å—è³æƒ…å ±ã€æ¥­ç¨®ã€åˆ¶ä½œä¼šç¤¾ãªã©ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿

### full_crawler.py
- å…¨37,259ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæ™‚é–“è¦ï¼‰
- ä¸­æ–­ãƒ»å†é–‹æ©Ÿèƒ½ä»˜ã

### simple_export.py
- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å„ç¨®å½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
- CSVã€JSONã€ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¯¾å¿œ

## âš ï¸ æ³¨æ„äº‹é …

1. **åˆ©ç”¨è¦ç´„ã®éµå®ˆ**: TCCã®åˆ©ç”¨è¦ç´„ã‚’å¿…ãšç¢ºèªã—ã¦ãã ã•ã„
2. **ã‚µãƒ¼ãƒãƒ¼è² è·**: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ™‚ã¯é©åˆ‡ãªé–“éš”ã‚’è¨­ã‘ã¦ãã ã•ã„
3. **ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°**: ãƒ‡ãƒ¼ã‚¿ã¯å–å¾—æ™‚ç‚¹ã®ã‚‚ã®ã§ã™
4. **å•†ç”¨åˆ©ç”¨**: å•†ç”¨åˆ©ç”¨å‰ã«TCCã«ç¢ºèªã‚’å–ã£ã¦ãã ã•ã„

## ğŸ“ å•ã„åˆã‚ã›

ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹å•ã„åˆã‚ã›ã¯ã€TCCã®å…¬å¼ã‚µã‚¤ãƒˆã¾ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
https://www.tcc.gr.jp/

## ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«å«ã¾ã‚Œã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚
ãƒ‡ãƒ¼ã‚¿ã®æ¨©åˆ©ã¯TCCã«å¸°å±ã—ã¾ã™ã€‚
"""
    return content

def create_data_summary():
    """ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ä½œæˆ"""
    # æœ€æ–°ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çµ±è¨ˆã‚’å–å¾—
    try:
        with open('tcc_data_100items_20250816_004700.json', 'r', encoding='utf-8') as f:
            basic_data = json.load(f)
    except:
        basic_data = []
    
    try:
        with open('tcc_enhanced_20250816_005213.json', 'r', encoding='utf-8') as f:
            detailed_data = json.load(f)
    except:
        detailed_data = []
    
    content = f"""TCC ã‚³ãƒ”ãƒ© ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼
{'='*60}
ä½œæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
{'-'*30}
åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(basic_data)}ä»¶
è©³ç´°ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(detailed_data)}ä»¶
TCCãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç·ä»¶æ•°: 37,259ä»¶ï¼ˆ2025å¹´8æœˆæ™‚ç‚¹ï¼‰

ğŸ“º åª’ä½“åˆ¥åˆ†å¸ƒï¼ˆåŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šï¼‰
{'-'*30}
"""
    
    # åª’ä½“åˆ¥çµ±è¨ˆ
    if basic_data:
        media_count = {}
        for item in basic_data:
            media = item.get('media', 'Unknown')
            media_count[media] = media_count.get(media, 0) + 1
        
        for media, count in sorted(media_count.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(basic_data)) * 100
            content += f"{media:10s}: {count:3d}ä»¶ ({percentage:5.1f}%)\n"
    
    content += f"""
ğŸ“… å¹´åº¦åˆ¥åˆ†å¸ƒ
{'-'*30}
"""
    
    # å¹´åº¦åˆ¥çµ±è¨ˆ
    if basic_data:
        year_count = {}
        for item in basic_data:
            year = str(item.get('year', 'Unknown'))
            year_count[year] = year_count.get(year, 0) + 1
        
        for year, count in sorted(year_count.items(), key=lambda x: x[0] if x[0] != 'Unknown' else '0', reverse=True):
            if year != 'Unknown':
                percentage = (count / len(basic_data)) * 100
                content += f"{year}å¹´: {count:3d}ä»¶ ({percentage:5.1f}%)\n"
    
    content += f"""
âœï¸ ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼æƒ…å ±
{'-'*30}
"""
    
    # ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼çµ±è¨ˆ
    if basic_data:
        copywriter_count = {}
        for item in basic_data:
            for cw in item.get('copywriters', []):
                name = cw.get('name', 'Unknown')
                copywriter_count[name] = copywriter_count.get(name, 0) + 1
        
        for copywriter, count in sorted(copywriter_count.items(), key=lambda x: x[1], reverse=True)[:10]:
            if copywriter != 'Unknown':
                content += f"{copywriter:20s}: {count:2d}ä»¶\n"
    
    content += f"""
ğŸ† è©³ç´°ãƒ‡ãƒ¼ã‚¿æƒ…å ±ï¼ˆè©³ç´°å–å¾—æ¸ˆã¿åˆ†ï¼‰
{'-'*30}
"""
    
    if detailed_data:
        award_count = {}
        industry_count = {}
        
        for item in detailed_data:
            detail_info = item.get('detail_info', {})
            if detail_info and 'error' not in detail_info:
                award = detail_info.get('award', '')
                if award:
                    award_count[award] = award_count.get(award, 0) + 1
                
                industry = detail_info.get('industry', '')
                if industry:
                    industry_count[industry] = industry_count.get(industry, 0) + 1
        
        if award_count:
            content += "å—è³æƒ…å ±:\n"
            for award, count in sorted(award_count.items(), key=lambda x: x[1], reverse=True):
                content += f"  {award}: {count}ä»¶\n"
        
        if industry_count:
            content += "\næ¥­ç¨®æƒ…å ±:\n"
            for industry, count in sorted(industry_count.items(), key=lambda x: x[1], reverse=True):
                content += f"  {industry}: {count}ä»¶\n"
    
    content += f"""
ğŸ’¡ ãƒ‡ãƒ¼ã‚¿æ´»ç”¨ã®ãƒ’ãƒ³ãƒˆ
{'-'*30}
1. åª’ä½“åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ: TVCM vs WEB ã®è¡¨ç¾æ‰‹æ³•ã®é•ã„
2. å¹´ä»£åˆ¥ã‚³ãƒ”ãƒ¼å¤‰é·: ç¤¾ä¼šæƒ…å‹¢ã¨ã‚³ãƒ”ãƒ¼ã®é–¢é€£æ€§
3. ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ç ”ç©¶: å€‹äººã®ã‚¹ã‚¿ã‚¤ãƒ«ã¨ä½œå“å‚¾å‘
4. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæˆ¦ç•¥: ãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥ã®ä¸€è²«æ€§ã¨å¤‰åŒ–
5. å—è³ä½œå“åˆ†æ: è©•ä¾¡åŸºæº–ã¨å‚¾å‘ã®å¤‰åŒ–

ğŸ“ˆ ä»Šå¾Œã®æ‹¡å¼µå¯èƒ½æ€§
{'-'*30}
- å…¨ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆ37,259ä»¶ï¼‰
- ãƒ†ã‚­ã‚¹ãƒˆè§£æã«ã‚ˆã‚‹è‡ªå‹•åˆ†é¡
- ç”»åƒãƒ‡ãƒ¼ã‚¿ã®åé›†ã¨åˆ†æ
- æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–
- é¡ä¼¼ä½œå“ã®æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 

{'='*60}
"""
    
    return content

def create_usage_guide():
    """ä½¿ç”¨æ–¹æ³•ã‚¬ã‚¤ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ä½œæˆ"""
    content = """# TCC ãƒ‡ãƒ¼ã‚¿ ä½¿ç”¨æ–¹æ³•ã‚¬ã‚¤ãƒ‰

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
```bash
# åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ï¼ˆJSONå½¢å¼ï¼‰
cat basic_data/tcc_data_100items_*.json | jq '.[0]'

# CSVå½¢å¼ã§è¡¨å½¢å¼è¡¨ç¤º
head -5 basic_data/tcc_export_*.csv
```

### 2. åˆ†æçµæœã®ç¢ºèª
```bash
# ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
cat analysis/tcc_summary_report_*.md

# è©³ç´°çµ±è¨ˆ
cat analysis/tcc_export_*_detailed.txt
```

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿å½¢å¼

### åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼ˆJSONï¼‰
```json
{
  "id": "2023352",
  "title": "ãƒ•ã‚¡ãƒ³ã‚±ãƒ«ã€€ä¼æ¥­ã€Œ10gã®é–¢ä¿‚ã€ç¯‡",
  "client": "ãƒ•ã‚¡ãƒ³ã‚±ãƒ«",
  "media": "WEB",
  "year": 2024,
  "detail_url": "https://www.tcc.gr.jp/copira/id/2023352/",
  "copywriters": [
    {
      "name": "é–¢é™½å­",
      "id": "34211997"
    }
  ]
}
```

### è©³ç´°ãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼ˆJSONï¼‰
```json
{
  "detail_info": {
    "advertiser": "ãƒ•ã‚¡ãƒ³ã‚±ãƒ«",
    "award": "TCCè³",
    "industry": "å¥åº·ãƒ»ç¾å®¹",
    "media_type": "WEB",
    "publication_year": "2024",
    "page_number": "42",
    "copywriter": "é–¢é™½å­",
    "agency": "åšå ±å ‚",
    "copy_content": "..."
  }
}
```

## ğŸ”§ ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½¿ç”¨æ–¹æ³•

### ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—
```bash
python scripts/tcc_table_scraper.py
```
- æœ€æ–°100ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
- CSVã€JSONã€åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ç”Ÿæˆ

#### è©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—
```bash
python scripts/detail_scraper.py
```
- è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰è¿½åŠ æƒ…å ±ã‚’å–å¾—
- å—è³æƒ…å ±ã€æ¥­ç¨®ã€åˆ¶ä½œä¼šç¤¾ãªã©ã‚’åé›†

#### å…¨ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ™‚é–“è¦ï¼‰
```bash
python scripts/full_crawler.py
```
- 37,259ä»¶å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ©Ÿèƒ½ä»˜ãï¼ˆä¸­æ–­ãƒ»å†é–‹å¯èƒ½ï¼‰

### ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

#### å„ç¨®å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
```bash
python scripts/simple_export.py
```
- CSVã€JSONã€ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›
- ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼åˆ¥ãƒªã‚¹ãƒˆã‚‚ç”Ÿæˆ

## ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†æã®ã‚¢ã‚¤ãƒ‡ã‚¢

### 1. åª’ä½“åˆ¥åˆ†æ
```python
import json
import pandas as pd

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with open('basic_data/tcc_data_100items_*.json') as f:
    data = json.load(f)

# åª’ä½“åˆ¥é›†è¨ˆ
df = pd.DataFrame(data)
media_counts = df['media'].value_counts()
print(media_counts)
```

### 2. å¹´ä»£åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰
```python
# å¹´åº¦åˆ¥é›†è¨ˆã¨ã‚°ãƒ©ãƒ•åŒ–
import matplotlib.pyplot as plt

year_counts = df['year'].value_counts().sort_index()
year_counts.plot(kind='bar', title='å¹´åº¦åˆ¥åºƒå‘Šä»¶æ•°')
plt.show()
```

### 3. ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼åˆ†æ
```python
# ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼åˆ¥ä½œå“æ•°
copywriter_data = []
for item in data:
    for cw in item.get('copywriters', []):
        copywriter_data.append({
            'name': cw['name'],
            'title': item['title'],
            'client': item['client'],
            'year': item['year']
        })

cw_df = pd.DataFrame(copywriter_data)
top_copywriters = cw_df['name'].value_counts().head(10)
print(top_copywriters)
```

### 4. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ¥åˆ†æ
```python
# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ¥ä½œå“å‚¾å‘
client_media = df.groupby('client')['media'].value_counts()
print(client_media)
```

## ğŸ” é«˜åº¦ãªæ´»ç”¨æ–¹æ³•

### ãƒ†ã‚­ã‚¹ãƒˆè§£æ
- ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
- æ„Ÿæƒ…åˆ†æã«ã‚ˆã‚‹å°è±¡åˆ†é¡
- é¡ä¼¼ä½œå“ã®æ¤œç´¢

### æ©Ÿæ¢°å­¦ç¿’å¿œç”¨
- æˆåŠŸä½œå“ã®ç‰¹å¾´åˆ†æ
- è‡ªå‹•ã‚¿ã‚°ä»˜ã‘
- ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ 

### å¯è¦–åŒ–
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æï¼ˆã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼-ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé–¢ä¿‚ï¼‰
- æ™‚ç³»åˆ—ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 

## âš ï¸ æ³¨æ„äº‹é …

### åˆ©ç”¨æ™‚ã®æ³¨æ„
1. **è‘—ä½œæ¨©**: ãƒ‡ãƒ¼ã‚¿ã®è‘—ä½œæ¨©ã¯TCCã«å¸°å±
2. **åˆ©ç”¨è¦ç´„**: TCCå…¬å¼ã‚µã‚¤ãƒˆã®åˆ©ç”¨è¦ç´„ã‚’éµå®ˆ
3. **å•†ç”¨åˆ©ç”¨**: äº‹å‰ã«TCCã¸ã®ç¢ºèªãŒå¿…è¦
4. **ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°**: éåº¦ãªè² è·ã‚’ã‹ã‘ãªã„

### ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- **æ–‡å­—åŒ–ã‘**: UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèª
- **ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆ**: å–å¾—æ™‚æœŸã«ã‚ˆã‚‹å·®ç•°ã®å¯èƒ½æ€§
- **ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚¨ãƒ©ãƒ¼**: ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª

## ğŸ“ ã‚µãƒãƒ¼ãƒˆ

- TCCå…¬å¼ã‚µã‚¤ãƒˆ: https://www.tcc.gr.jp/
- æŠ€è¡“çš„ãªè³ªå•: å„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§

## ğŸ”„ ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ

å®šæœŸçš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹å ´åˆ:
1. ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å†å®Ÿè¡Œ
2. æ–°æ—§ãƒ‡ãƒ¼ã‚¿ã®æ¯”è¼ƒ
3. å·®åˆ†ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºãƒ»åˆ†æ
"""
    return content

if __name__ == "__main__":
    package_dir = create_final_data_package()
    print(f"\nğŸ“¦ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒä½œæˆã•ã‚Œã¾ã—ãŸ: {package_dir}")
    print("ğŸ¯ ã“ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«ã¯ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã¨åˆ†æçµæœãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
    print("ğŸ“– è©³ç´°ãªä½¿ç”¨æ–¹æ³•ã¯ README.md ã‚’ã”ç¢ºèªãã ã•ã„")