"""
Final System Validation and Testing
æœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼ã¨ãƒ†ã‚¹ãƒˆ

å®Œæˆã—ãŸã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼AIã‚·ã‚¹ãƒ†ãƒ ã®
åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã¨æ€§èƒ½æ¤œè¨¼
"""

import json
import asyncio
import time
from typing import Dict, List, Tuple
from dataclasses import asdict
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
import logging

# å®Œæˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from advanced_copywriter_ai_system import ProductionCopywriterAI, AdvancedCopywritingRequest

class SystemValidator:
    """ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, system: ProductionCopywriterAI):
        self.system = system
        self.test_results = []
        self.performance_metrics = {}
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©
        self.test_cases = [
            {
                'name': 'Premium Food Product',
                'copywriter': 'ç³¸äº•é‡é‡Œ',
                'product': 'æœ‰æ©Ÿé‡èœã‚¸ãƒ¥ãƒ¼ã‚¹',
                'target': 'å¥åº·å¿—å‘ã®30ä»£å¥³æ€§',
                'content_type': 'Webåºƒå‘Š',
                'key_messages': ['è‡ªç„¶ã®æµã¿', 'å¥åº·ç¾å®¹', 'æ¯æ—¥ã®ç¿’æ…£'],
                'expected_elements': ['è¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾', 'ç”Ÿæ´»ææ¡ˆ', 'æ¸©ã‹ã¿']
            },
            {
                'name': 'Technology Product', 
                'copywriter': 'ä»²ç•‘è²´å¿—',
                'product': 'ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã‚¢ãƒ—ãƒª',
                'target': '20ä»£ã®ãƒ‡ã‚¸ã‚¿ãƒ«ãƒã‚¤ãƒ†ã‚£ãƒ–',
                'content_type': 'SNSåºƒå‘Š',
                'key_messages': ['ç°¡å˜æ“ä½œ', 'é©æ–°çš„', 'ã¤ãªãŒã‚Š'],
                'expected_elements': ['ã‚·ãƒ³ãƒ—ãƒ«è¡¨ç¾', 'å°è±¡çš„', 'æ™®éçš„']
            },
            {
                'name': 'Luxury Brand',
                'copywriter': 'ç³¸äº•é‡é‡Œ',
                'product': 'ãƒ—ãƒ¬ãƒŸã‚¢ãƒ æ™‚è¨ˆ',
                'target': '40-50ä»£ç”·æ€§çµŒå–¶å±¤',
                'content_type': 'é›‘èªŒåºƒå‘Š',
                'key_messages': ['è·äººæŠ€', 'ä¼çµ±', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'],
                'expected_elements': ['ä¸Šè³ªãªè¡¨ç¾', 'ãƒ–ãƒ©ãƒ³ãƒ‰ä¾¡å€¤', 'ä¿¡é ¼æ„Ÿ']
            }
        ]
        
        logging.info("System validator initialized with test cases")
    
    async def run_comprehensive_validation(self) -> Dict:
        """åŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼å®Ÿè¡Œ"""
        
        print("ğŸ” Starting Comprehensive System Validation")
        print("=" * 60)
        
        validation_results = {
            'start_time': datetime.now().isoformat(),
            'system_info': await self.validate_system_setup(),
            'functionality_tests': await self.run_functionality_tests(),
            'performance_tests': await self.run_performance_tests(),
            'quality_tests': await self.run_quality_tests(),
            'stress_tests': await self.run_stress_tests(),
            'final_assessment': None
        }
        
        # æœ€çµ‚è©•ä¾¡
        validation_results['final_assessment'] = self.generate_final_assessment(validation_results)
        validation_results['end_time'] = datetime.now().isoformat()
        
        return validation_results
    
    async def validate_system_setup(self) -> Dict:
        """ã‚·ã‚¹ãƒ†ãƒ è¨­å®šæ¤œè¨¼"""
        print("\nğŸ“‹ System Setup Validation")
        
        setup_validation = {
            'available_copywriters': len(self.system.get_available_copywriters()),
            'copywriters_list': self.system.get_available_copywriters(),
            'database_connectivity': False,
            'style_analysis_loaded': False,
            'api_availability': hasattr(self.system.generator, 'client') and self.system.generator.client is not None
        }
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
        try:
            profiles = [self.system.get_copywriter_profile(name) 
                       for name in setup_validation['copywriters_list']]
            setup_validation['database_connectivity'] = any(p is not None for p in profiles)
        except Exception as e:
            logging.error(f"Database connectivity test failed: {e}")
        
        # ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æãƒ‡ãƒ¼ã‚¿ç¢ºèª
        try:
            if setup_validation['copywriters_list']:
                first_profile = self.system.get_copywriter_profile(setup_validation['copywriters_list'][0])
                setup_validation['style_analysis_loaded'] = (
                    first_profile is not None and 
                    'style_metrics' in first_profile
                )
        except Exception as e:
            logging.error(f"Style analysis validation failed: {e}")
        
        print(f"  âœ“ Available Copywriters: {setup_validation['available_copywriters']}")
        print(f"  âœ“ Database Connectivity: {setup_validation['database_connectivity']}")
        print(f"  âœ“ Style Analysis Loaded: {setup_validation['style_analysis_loaded']}")
        print(f"  âœ“ API Availability: {setup_validation['api_availability']}")
        
        return setup_validation
    
    async def run_functionality_tests(self) -> Dict:
        """æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("\nâš™ï¸  Functionality Tests")
        
        functionality_results = {
            'basic_generation': False,
            'persona_switching': False,
            'style_consistency': False,
            'error_handling': False,
            'test_details': []
        }
        
        # åŸºæœ¬ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        try:
            if self.system.get_available_copywriters():
                test_copywriter = self.system.get_available_copywriters()[0]
                result = await self.system.create_professional_copy(
                    copywriter_name=test_copywriter,
                    product_service="ãƒ†ã‚¹ãƒˆå•†å“",
                    target_audience="ãƒ†ã‚¹ãƒˆå±¤",
                    content_type="ãƒ†ã‚¹ãƒˆåºƒå‘Š"
                )
                functionality_results['basic_generation'] = bool(result.primary_copy)
                print(f"  âœ“ Basic Generation: {'PASS' if functionality_results['basic_generation'] else 'FAIL'}")
            
        except Exception as e:
            logging.error(f"Basic generation test failed: {e}")
            print(f"  âœ— Basic Generation: FAIL - {e}")
        
        # ãƒšãƒ«ã‚½ãƒŠåˆ‡ã‚Šæ›¿ãˆãƒ†ã‚¹ãƒˆ
        try:
            available = self.system.get_available_copywriters()
            if len(available) >= 2:
                results = []
                for copywriter in available[:2]:
                    result = await self.system.create_professional_copy(
                        copywriter_name=copywriter,
                        product_service="åŒä¸€å•†å“",
                        target_audience="åŒä¸€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ", 
                        content_type="åŒä¸€åª’ä½“"
                    )
                    results.append(result.primary_copy)
                
                # ç•°ãªã‚‹å‡ºåŠ›ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                functionality_results['persona_switching'] = len(set(results)) > 1
                print(f"  âœ“ Persona Switching: {'PASS' if functionality_results['persona_switching'] else 'FAIL'}")
            
        except Exception as e:
            logging.error(f"Persona switching test failed: {e}")
            print(f"  âœ— Persona Switching: FAIL - {e}")
        
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        try:
            # å­˜åœ¨ã—ãªã„ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã®ãƒ†ã‚¹ãƒˆ
            try:
                await self.system.create_professional_copy(
                    copywriter_name="å­˜åœ¨ã—ãªã„ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼",
                    product_service="ãƒ†ã‚¹ãƒˆ",
                    target_audience="ãƒ†ã‚¹ãƒˆ",
                    content_type="ãƒ†ã‚¹ãƒˆ"
                )
                functionality_results['error_handling'] = False
            except (ValueError, KeyError):
                functionality_results['error_handling'] = True
            
            print(f"  âœ“ Error Handling: {'PASS' if functionality_results['error_handling'] else 'FAIL'}")
            
        except Exception as e:
            logging.error(f"Error handling test failed: {e}")
            print(f"  âœ— Error Handling: FAIL - {e}")
        
        return functionality_results
    
    async def run_performance_tests(self) -> Dict:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("\nğŸš€ Performance Tests")
        
        performance_results = {
            'generation_speed': [],
            'memory_usage': 'Not measured',
            'concurrent_handling': False,
            'average_response_time': 0.0
        }
        
        # ç”Ÿæˆé€Ÿåº¦ãƒ†ã‚¹ãƒˆ
        if self.system.get_available_copywriters():
            test_copywriter = self.system.get_available_copywriters()[0]
            
            for i in range(3):
                start_time = time.time()
                try:
                    result = await self.system.create_professional_copy(
                        copywriter_name=test_copywriter,
                        product_service=f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå•†å“{i}",
                        target_audience="ãƒ†ã‚¹ãƒˆå±¤",
                        content_type="ãƒ†ã‚¹ãƒˆåºƒå‘Š"
                    )
                    end_time = time.time()
                    response_time = end_time - start_time
                    performance_results['generation_speed'].append(response_time)
                    print(f"  âœ“ Generation {i+1}: {response_time:.2f}s")
                    
                except Exception as e:
                    logging.error(f"Performance test {i} failed: {e}")
                    performance_results['generation_speed'].append(None)
        
        # å¹³å‡å¿œç­”æ™‚é–“è¨ˆç®—
        valid_times = [t for t in performance_results['generation_speed'] if t is not None]
        if valid_times:
            performance_results['average_response_time'] = sum(valid_times) / len(valid_times)
            print(f"  ğŸ“Š Average Response Time: {performance_results['average_response_time']:.2f}s")
        
        return performance_results
    
    async def run_quality_tests(self) -> Dict:
        """å“è³ªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("\nğŸ¯ Quality Tests")
        
        quality_results = {
            'test_cases': [],
            'overall_quality_score': 0.0,
            'style_accuracy_average': 0.0,
            'effectiveness_average': 0.0
        }
        
        total_style_accuracy = 0
        total_effectiveness = 0
        valid_tests = 0
        
        for i, test_case in enumerate(self.test_cases):
            print(f"  ğŸ§ª Test Case {i+1}: {test_case['name']}")
            
            case_result = {
                'name': test_case['name'],
                'copywriter': test_case['copywriter'],
                'success': False,
                'generated_copy': '',
                'quality_scores': {},
                'style_analysis': {}
            }
            
            try:
                # ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                if test_case['copywriter'] not in self.system.get_available_copywriters():
                    print(f"    âš ï¸  Copywriter {test_case['copywriter']} not available, using fallback")
                    test_case['copywriter'] = self.system.get_available_copywriters()[0]
                
                result = await self.system.create_professional_copy(
                    copywriter_name=test_case['copywriter'],
                    product_service=test_case['product'],
                    target_audience=test_case['target'],
                    content_type=test_case['content_type'],
                    key_messages=test_case['key_messages'],
                    style_intensity=0.8,
                    creativity_level=0.7
                )
                
                case_result['success'] = True
                case_result['generated_copy'] = result.primary_copy
                case_result['quality_scores'] = {
                    'style_accuracy': result.style_accuracy_score,
                    'effectiveness': result.predicted_effectiveness,
                    'readability': result.readability_score,
                    'emotional_impact': result.emotional_impact_score,
                    'confidence': result.confidence_score
                }
                
                # æœŸå¾…è¦ç´ ã®ç¢ºèª
                expected_found = sum(1 for element in test_case['expected_elements'] 
                                   if any(keyword in result.primary_copy.lower() 
                                         for keyword in element.lower().split()))
                
                case_result['style_analysis'] = {
                    'expected_elements_found': expected_found,
                    'total_expected_elements': len(test_case['expected_elements']),
                    'key_messages_included': sum(1 for msg in test_case['key_messages']
                                               if msg in result.primary_copy)
                }
                
                # çµ±è¨ˆã«è¿½åŠ 
                total_style_accuracy += result.style_accuracy_score
                total_effectiveness += result.predicted_effectiveness
                valid_tests += 1
                
                print(f"    âœ“ Generated: {result.primary_copy[:50]}...")
                print(f"    ğŸ“Š Quality: Style={result.style_accuracy_score:.1f}%, Effectiveness={result.predicted_effectiveness:.1f}%")
                
            except Exception as e:
                logging.error(f"Quality test case {i+1} failed: {e}")
                print(f"    âœ— Failed: {e}")
            
            quality_results['test_cases'].append(case_result)
        
        # å¹³å‡å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
        if valid_tests > 0:
            quality_results['style_accuracy_average'] = total_style_accuracy / valid_tests
            quality_results['effectiveness_average'] = total_effectiveness / valid_tests
            quality_results['overall_quality_score'] = (
                quality_results['style_accuracy_average'] + 
                quality_results['effectiveness_average']
            ) / 2
        
        print(f"\n  ğŸ“ˆ Overall Quality Summary:")
        print(f"    Average Style Accuracy: {quality_results['style_accuracy_average']:.1f}%")
        print(f"    Average Effectiveness: {quality_results['effectiveness_average']:.1f}%")
        print(f"    Overall Quality Score: {quality_results['overall_quality_score']:.1f}%")
        
        return quality_results
    
    async def run_stress_tests(self) -> Dict:
        """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("\nğŸ’ª Stress Tests")
        
        stress_results = {
            'concurrent_requests': False,
            'large_input_handling': False,
            'rapid_successive_calls': False,
            'edge_cases': []
        }
        
        # å¤§é‡å…¥åŠ›ãƒ†ã‚¹ãƒˆ
        try:
            if self.system.get_available_copywriters():
                long_product_desc = "éå¸¸ã«é•·ã„å•†å“èª¬æ˜" * 100
                result = await self.system.create_professional_copy(
                    copywriter_name=self.system.get_available_copywriters()[0],
                    product_service=long_product_desc,
                    target_audience="ãƒ†ã‚¹ãƒˆå±¤",
                    content_type="ãƒ†ã‚¹ãƒˆåºƒå‘Š"
                )
                stress_results['large_input_handling'] = bool(result.primary_copy)
                print(f"  âœ“ Large Input Handling: {'PASS' if stress_results['large_input_handling'] else 'FAIL'}")
            
        except Exception as e:
            logging.error(f"Large input test failed: {e}")
            print(f"  âœ— Large Input Handling: FAIL - {e}")
        
        # é€£ç¶šå‘¼ã³å‡ºã—ãƒ†ã‚¹ãƒˆ
        try:
            if self.system.get_available_copywriters():
                rapid_results = []
                for i in range(5):
                    result = await self.system.create_professional_copy(
                        copywriter_name=self.system.get_available_copywriters()[0],
                        product_service=f"é€£ç¶šãƒ†ã‚¹ãƒˆå•†å“{i}",
                        target_audience="ãƒ†ã‚¹ãƒˆå±¤",
                        content_type="ãƒ†ã‚¹ãƒˆåºƒå‘Š"
                    )
                    rapid_results.append(bool(result.primary_copy))
                
                stress_results['rapid_successive_calls'] = all(rapid_results)
                print(f"  âœ“ Rapid Successive Calls: {'PASS' if stress_results['rapid_successive_calls'] else 'FAIL'}")
            
        except Exception as e:
            logging.error(f"Rapid successive calls test failed: {e}")
            print(f"  âœ— Rapid Successive Calls: FAIL - {e}")
        
        return stress_results
    
    def generate_final_assessment(self, validation_results: Dict) -> Dict:
        """æœ€çµ‚è©•ä¾¡ç”Ÿæˆ"""
        
        assessment = {
            'overall_status': 'UNKNOWN',
            'system_readiness': 'NOT_READY',
            'strengths': [],
            'weaknesses': [],
            'recommendations': [],
            'production_readiness_score': 0.0
        }
        
        # å„ãƒ†ã‚¹ãƒˆçµæœã®è©•ä¾¡
        system_info = validation_results.get('system_info', {})
        functionality = validation_results.get('functionality_tests', {})
        performance = validation_results.get('performance_tests', {})
        quality = validation_results.get('quality_tests', {})
        stress = validation_results.get('stress_tests', {})
        
        # å¼·ã¿
        if system_info.get('database_connectivity'):
            assessment['strengths'].append("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆæ©Ÿèƒ½")
        
        if system_info.get('style_analysis_loaded'):
            assessment['strengths'].append("ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æãƒ‡ãƒ¼ã‚¿æ´»ç”¨")
        
        if functionality.get('basic_generation'):
            assessment['strengths'].append("åŸºæœ¬çš„ãªã‚³ãƒ”ãƒ¼ç”Ÿæˆæ©Ÿèƒ½")
        
        if functionality.get('persona_switching'):
            assessment['strengths'].append("ãƒšãƒ«ã‚½ãƒŠåˆ‡ã‚Šæ›¿ãˆæ©Ÿèƒ½")
        
        if quality.get('overall_quality_score', 0) > 50:
            assessment['strengths'].append("å“è³ªã‚¹ã‚³ã‚¢ãŒåŸºæº–å€¤ã‚’è¶…é")
        
        # å¼±ã¿ãƒ»æ¨å¥¨äº‹é …
        if not system_info.get('api_availability'):
            assessment['weaknesses'].append("AI APIæ¥ç¶šä¸å¯ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œï¼‰")
            assessment['recommendations'].append("Claude APIæ¥ç¶šã®è¨­å®š")
        
        if system_info.get('available_copywriters', 0) < 5:
            assessment['weaknesses'].append("åˆ©ç”¨å¯èƒ½ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼æ•°ãŒå°‘ãªã„")
            assessment['recommendations'].append("TCCãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®å®Ÿãƒ‡ãƒ¼ã‚¿åé›†")
        
        if quality.get('style_accuracy_average', 0) < 70:
            assessment['weaknesses'].append("ã‚¹ã‚¿ã‚¤ãƒ«å†ç¾ç²¾åº¦ãŒä¸è¶³")
            assessment['recommendations'].append("ãƒšãƒ«ã‚½ãƒŠãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åŒ–")
        
        if not functionality.get('error_handling'):
            assessment['weaknesses'].append("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒä¸ååˆ†")
            assessment['recommendations'].append("ä¾‹å¤–å‡¦ç†ã®å¼·åŒ–")
        
        # æœ¬æ ¼é‹ç”¨æº–å‚™åº¦ã‚¹ã‚³ã‚¢ç®—å‡º
        scores = []
        
        if system_info.get('database_connectivity'): scores.append(20)
        if system_info.get('style_analysis_loaded'): scores.append(15)
        if functionality.get('basic_generation'): scores.append(25)
        if functionality.get('persona_switching'): scores.append(15)
        if quality.get('overall_quality_score', 0) > 50: scores.append(25)
        
        assessment['production_readiness_score'] = sum(scores)
        
        # ç·åˆè©•ä¾¡åˆ¤å®š
        if assessment['production_readiness_score'] >= 80:
            assessment['overall_status'] = 'EXCELLENT'
            assessment['system_readiness'] = 'PRODUCTION_READY'
        elif assessment['production_readiness_score'] >= 60:
            assessment['overall_status'] = 'GOOD'
            assessment['system_readiness'] = 'STAGING_READY'
        elif assessment['production_readiness_score'] >= 40:
            assessment['overall_status'] = 'FAIR'
            assessment['system_readiness'] = 'DEVELOPMENT_READY'
        else:
            assessment['overall_status'] = 'POOR'
            assessment['system_readiness'] = 'NOT_READY'
        
        return assessment
    
    def generate_validation_report(self, results: Dict) -> str:
        """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        timestamp = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
        
        report = f"""
# ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼AIã‚·ã‚¹ãƒ†ãƒ  - æœ€çµ‚æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ
## æ¤œè¨¼æ—¥æ™‚: {timestamp}

## ğŸ¯ ç·åˆè©•ä¾¡
**ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹**: {results['final_assessment']['overall_status']}
**é‹ç”¨æº–å‚™åº¦**: {results['final_assessment']['system_readiness']}
**æº–å‚™åº¦ã‚¹ã‚³ã‚¢**: {results['final_assessment']['production_readiness_score']}/100

## âœ… ã‚·ã‚¹ãƒ†ãƒ å¼·ã¿
{chr(10).join(f'â€¢ {strength}' for strength in results['final_assessment']['strengths'])}

## âš ï¸  æ”¹å–„ç‚¹
{chr(10).join(f'â€¢ {weakness}' for weakness in results['final_assessment']['weaknesses'])}

## ğŸ’¡ æ¨å¥¨äº‹é …
{chr(10).join(f'â€¢ {rec}' for rec in results['final_assessment']['recommendations'])}

## ğŸ“Š è©³ç´°ãƒ†ã‚¹ãƒˆçµæœ

### ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
- åˆ©ç”¨å¯èƒ½ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼: {results['system_info']['available_copywriters']}äºº
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š: {'âœ“' if results['system_info']['database_connectivity'] else 'âœ—'}
- ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æãƒ‡ãƒ¼ã‚¿: {'âœ“' if results['system_info']['style_analysis_loaded'] else 'âœ—'}
- APIæ¥ç¶š: {'âœ“' if results['system_info']['api_availability'] else 'âœ—'}

### æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
- åŸºæœ¬ç”Ÿæˆ: {'PASS' if results['functionality_tests']['basic_generation'] else 'FAIL'}
- ãƒšãƒ«ã‚½ãƒŠåˆ‡æ›¿: {'PASS' if results['functionality_tests']['persona_switching'] else 'FAIL'}
- ã‚¨ãƒ©ãƒ¼å‡¦ç†: {'PASS' if results['functionality_tests']['error_handling'] else 'FAIL'}

### å“è³ªãƒ†ã‚¹ãƒˆ
- å¹³å‡ã‚¹ã‚¿ã‚¤ãƒ«ç²¾åº¦: {results['quality_tests']['style_accuracy_average']:.1f}%
- å¹³å‡åŠ¹æœäºˆæ¸¬: {results['quality_tests']['effectiveness_average']:.1f}%
- ç·åˆå“è³ªã‚¹ã‚³ã‚¢: {results['quality_tests']['overall_quality_score']:.1f}%

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- å¹³å‡å¿œç­”æ™‚é–“: {results['performance_tests']['average_response_time']:.2f}ç§’
- ç”ŸæˆæˆåŠŸç‡: {len([t for t in results['performance_tests']['generation_speed'] if t is not None])}/{len(results['performance_tests']['generation_speed'])}

## ğŸ çµè«–
{'æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯ç¾æ™‚ç‚¹ã§åŸºæœ¬çš„ãªæ©Ÿèƒ½ã‚’å®Ÿç¾ã—ã¦ãŠã‚Šã€ã•ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿åé›†ã¨APIçµ±åˆã«ã‚ˆã‚Šæœ¬æ ¼é‹ç”¨ãƒ¬ãƒ™ãƒ«ã«åˆ°é”å¯èƒ½ã§ã™ã€‚' if results['final_assessment']['production_readiness_score'] >= 40 else 'åŸºæœ¬æ©Ÿèƒ½ã¯å‹•ä½œã™ã‚‹ã‚‚ã®ã®ã€æœ¬æ ¼é‹ç”¨ã«ã¯ã•ã‚‰ãªã‚‹é–‹ç™ºãŒå¿…è¦ã§ã™ã€‚'}

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*
        """.strip()
        
        return report

async def run_final_validation():
    """æœ€çµ‚æ¤œè¨¼å®Ÿè¡Œ"""
    print("ğŸš€ Final System Validation and Testing")
    print("=" * 80)
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = ProductionCopywriterAI(
        db_path='/Users/naoki/tcc_copyworks.db',
        analysis_path='/Users/naoki/copywriter_style_analysis_20250810_000147.json'
    )
    
    # æ¤œè¨¼å™¨åˆæœŸåŒ–
    validator = SystemValidator(system)
    
    # åŒ…æ‹¬çš„æ¤œè¨¼å®Ÿè¡Œ
    results = await validator.run_comprehensive_validation()
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = validator.generate_validation_report(results)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    report_filename = f"/Users/naoki/final_validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write(report)
    
    results_filename = f"/Users/naoki/validation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(results_filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # æœ€çµ‚ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "=" * 80)
    print("ğŸ† FINAL SYSTEM VALIDATION COMPLETE")
    print("=" * 80)
    
    assessment = results['final_assessment']
    print(f"ğŸ“‹ Overall Status: {assessment['overall_status']}")
    print(f"ğŸ¯ System Readiness: {assessment['system_readiness']}")
    print(f"ğŸ“Š Readiness Score: {assessment['production_readiness_score']}/100")
    
    print(f"\nğŸ“„ Reports Generated:")
    print(f"  â€¢ Validation Report: {report_filename}")
    print(f"  â€¢ Detailed Results: {results_filename}")
    
    if assessment['production_readiness_score'] >= 60:
        print(f"\nğŸ‰ SYSTEM READY FOR NEXT PHASE!")
    else:
        print(f"\nâš ï¸  SYSTEM REQUIRES FURTHER DEVELOPMENT")
    
    print("=" * 80)
    
    return results, report

if __name__ == "__main__":
    # æœ€çµ‚æ¤œè¨¼å®Ÿè¡Œ
    validation_results, validation_report = asyncio.run(run_final_validation())