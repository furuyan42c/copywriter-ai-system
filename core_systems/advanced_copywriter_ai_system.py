"""
Advanced Copywriter AI System - Production Ready
æœ¬æ ¼çš„ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼AIã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Œæˆç‰ˆï¼‰

å®Ÿéš›ã®TCCãƒ‡ãƒ¼ã‚¿ã¨ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æã‚’çµ±åˆã—ãŸ
é«˜ç²¾åº¦ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import sqlite3
import numpy as np
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import re
from collections import Counter
import logging
import asyncio

# Claude APIç”¨ï¼ˆå®Ÿéš›ã®APIã‚­ãƒ¼ãŒå¿…è¦ï¼‰
try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

@dataclass
class AdvancedCopywritingRequest:
    """é«˜åº¦ãªã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ä¾é ¼æ§‹é€ """
    # åŸºæœ¬æƒ…å ±
    copywriter_persona: str
    content_type: str
    product_service: str
    target_audience: str
    
    # è©³ç´°è¨­å®š
    style_intensity: float  # 0.0-1.0 (ãƒšãƒ«ã‚½ãƒŠç‰¹å¾´ã®å¼·åº¦)
    creativity_level: float  # 0.0-1.0 (å‰µé€ æ€§ãƒ¬ãƒ™ãƒ«)
    length_preference: str  # 'short', 'medium', 'long'
    tone_preference: str   # 'formal', 'casual', 'emotional', 'rational'
    
    # åˆ¶ç´„ãƒ»è¦ä»¶
    key_messages: List[str]
    avoid_words: List[str]
    target_metrics: Optional[Dict[str, float]]  # æƒ³å®šæŒ‡æ¨™ï¼ˆèª­ã¿ã‚„ã™ã•ç­‰ï¼‰
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    brand_guidelines: Optional[str]
    competitive_context: Optional[str]
    cultural_considerations: Optional[str]

@dataclass
class AdvancedCopywritingResult:
    """é«˜åº¦ãªã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°çµæœ"""
    # ç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    primary_copy: str
    alternative_versions: List[str]
    
    # å“è³ªæŒ‡æ¨™
    style_accuracy_score: float
    predicted_effectiveness: float
    readability_score: float
    emotional_impact_score: float
    
    # åˆ†ææƒ…å ±
    style_elements_detected: List[str]
    keyword_optimization: Dict[str, float]
    target_alignment: Dict[str, float]
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    generation_metadata: Dict
    confidence_score: float
    recommended_usage: List[str]

class PersonaDatabase:
    """å¼·åŒ–ã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"""
    
    def __init__(self, db_path: str, analysis_data_path: str):
        self.db_path = db_path
        self.analysis_data_path = analysis_data_path
        self.load_enhanced_personas()
    
    def load_enhanced_personas(self):
        """å¼·åŒ–ã•ã‚ŒãŸãƒšãƒ«ã‚½ãƒŠãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        # ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æçµæœã®èª­ã¿è¾¼ã¿
        try:
            with open(self.analysis_data_path, 'r', encoding='utf-8') as f:
                self.style_analysis = json.load(f)
        except FileNotFoundError:
            self.style_analysis = {}
            logging.warning("Style analysis data not found, using fallback")
        
        # TCCãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®å®Ÿä½œå“èª­ã¿è¾¼ã¿
        self.load_actual_works()
        
        # çµ±åˆãƒšãƒ«ã‚½ãƒŠãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹ç¯‰
        self.build_integrated_personas()
    
    def load_actual_works(self):
        """å®Ÿéš›ã®ä½œå“ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT copywriter, copy_text, client, industry, media_type, year, award
                FROM copy_works
                WHERE copy_text IS NOT NULL AND copy_text != ""
            ''')
            
            self.actual_works = {}
            for row in cursor.fetchall():
                copywriter = row[0]
                if copywriter not in self.actual_works:
                    self.actual_works[copywriter] = []
                
                self.actual_works[copywriter].append({
                    'copy_text': row[1],
                    'client': row[2],
                    'industry': row[3],
                    'media_type': row[4],
                    'year': row[5],
                    'award': row[6]
                })
            
            conn.close()
            logging.info(f"Loaded actual works for {len(self.actual_works)} copywriters")
            
        except Exception as e:
            logging.error(f"Error loading actual works: {e}")
            self.actual_works = {}
    
    def build_integrated_personas(self):
        """çµ±åˆãƒšãƒ«ã‚½ãƒŠãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ§‹ç¯‰"""
        self.integrated_personas = {}
        
        # ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æãƒ‡ãƒ¼ã‚¿ã¨ã®çµ±åˆ
        if 'copywriter_analyses' in self.style_analysis:
            for name, analysis in self.style_analysis['copywriter_analyses'].items():
                
                # å®Ÿä½œå“ã‚µãƒ³ãƒ—ãƒ«
                work_samples = self.actual_works.get(name, [])[:5]  # æœ€å¤§5ä½œå“
                
                # çµ±åˆãƒšãƒ«ã‚½ãƒŠãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                integrated_persona = {
                    'name': name,
                    'style_metrics': analysis,
                    'work_samples': work_samples,
                    'writing_patterns': self.extract_writing_patterns(name, work_samples),
                    'signature_elements': self.identify_signature_elements(analysis),
                    'generation_prompts': self.create_generation_prompts(name, analysis, work_samples)
                }
                
                self.integrated_personas[name] = integrated_persona
        
        logging.info(f"Built integrated personas for {len(self.integrated_personas)} copywriters")
    
    def extract_writing_patterns(self, name: str, works: List[Dict]) -> Dict:
        """ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º"""
        if not works:
            return {}
        
        patterns = {
            'common_structures': [],
            'typical_openings': [],
            'characteristic_endings': [],
            'preferred_expressions': [],
            'sentence_patterns': []
        }
        
        for work in works:
            text = work['copy_text']
            
            # æ–‡ã®æ§‹é€ åˆ†æ
            sentences = [s.strip() for s in re.split(r'[ã€‚ï¼ï¼Ÿ]', text) if s.strip()]
            
            if sentences:
                patterns['typical_openings'].append(sentences[0][:10])
                if len(sentences) > 1:
                    patterns['characteristic_endings'].append(sentences[-1][-10:])
            
            # ç‰¹å¾´çš„è¡¨ç¾ã®æŠ½å‡º
            expressions = re.findall(r'[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾ ]{2,6}', text)
            patterns['preferred_expressions'].extend(expressions)
        
        # é »åº¦åˆ†æ
        for key in ['typical_openings', 'characteristic_endings', 'preferred_expressions']:
            counter = Counter(patterns[key])
            patterns[key] = [item for item, count in counter.most_common(3)]
        
        return patterns
    
    def identify_signature_elements(self, analysis: Dict) -> List[str]:
        """ã‚·ã‚°ãƒãƒãƒ£ãƒ¼è¦ç´ ç‰¹å®š"""
        elements = []
        
        # çµ±è¨ˆçš„ç‰¹å¾´ã‹ã‚‰ã®æŠ½å‡º
        if analysis.get('vocabulary_richness', 0) > 0.7:
            elements.append('é«˜ã„èªå½™å¤šæ§˜æ€§')
        
        if analysis.get('emotional_tone_score', 0) > 50:
            elements.append('æ„Ÿæƒ…çš„è¡¨ç¾é‡è¦–')
        
        if analysis.get('readability_score', 0) > 70:
            elements.append('é«˜ã„èª­ã¿ã‚„ã™ã•')
        
        # ãƒˆãƒƒãƒ—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ç‰¹å¾´æŠ½å‡º
        top_keywords = analysis.get('top_keywords', [])
        if top_keywords:
            elements.append(f"é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join([kw[0] for kw in top_keywords[:3]])}")
        
        return elements
    
    def create_generation_prompts(self, name: str, analysis: Dict, works: List[Dict]) -> Dict:
        """ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        
        # ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã®è¨€èªåŒ–
        style_description = f"""
{name}ã®ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã‚¹ã‚¿ã‚¤ãƒ«:

çµ±è¨ˆçš„ç‰¹å¾´:
- å¹³å‡ã‚³ãƒ”ãƒ¼é•·: {analysis.get('avg_copy_length', 0):.0f}æ–‡å­—
- èª­ã¿ã‚„ã™ã•ã‚¹ã‚³ã‚¢: {analysis.get('readability_score', 0):.1f}
- æ„Ÿæƒ…çš„ãƒˆãƒ¼ãƒ³: {analysis.get('emotional_tone_score', 0):.1f}%
- èªå½™å¤šæ§˜æ€§: {analysis.get('vocabulary_richness', 0):.3f}

ä¸»è¦ãƒ†ãƒ¼ãƒ: {', '.join(analysis.get('common_themes', []))}
ãƒˆãƒƒãƒ—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join([kw[0] for kw in analysis.get('top_keywords', [])[:5]])}
æ´»å‹•æœŸé–“: {analysis.get('active_period', ['', ''])[0]}-{analysis.get('active_period', ['', ''])[1]}
        """.strip()
        
        # å®Ÿä½œå“ä¾‹
        work_examples = ""
        if works:
            work_examples = "å®Ÿéš›ã®ä½œå“ä¾‹:\n"
            for i, work in enumerate(works[:3], 1):
                work_examples += f"{i}. ã€Œ{work['copy_text']}ã€ï¼ˆ{work.get('client', 'ä¸æ˜')}ãƒ»{work.get('year', 'ä¸æ˜')}å¹´ï¼‰\n"
        
        # ç”ŸæˆæŒ‡ç¤ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        generation_prompt = f"""
ã‚ãªãŸã¯{name}ã®ã‚¹ã‚¿ã‚¤ãƒ«ã§ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã‚’è¡Œã†AIã§ã™ã€‚

{style_description}

{work_examples}

ä»¥ä¸‹ã®ç‰¹å¾´ã‚’å¿…ãšåæ˜ ã—ã¦ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„:
- {name}ç‰¹æœ‰ã®è¨€è‘‰é¸ã³ã¨è¡¨ç¾æ–¹æ³•
- çµ±è¨ˆçš„ç‰¹å¾´ã«åˆè‡´ã—ãŸæ–‡å­—æ•°ãƒ»æ–‡ä½“
- å®Ÿä½œå“ã«è¦‹ã‚‰ã‚Œã‚‹ãƒˆãƒ¼ãƒ³ãƒ»è¨´æ±‚æ–¹æ³•
- {name}ã‚‰ã—ã„ç‹¬è‡ªæ€§ã¨å‰µé€ æ€§

ã‚³ãƒ”ãƒ¼ä½œæˆæ™‚ã¯ã€å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹æƒ…å ±ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã€åª’ä½“ã‚’è€ƒæ…®ã—ã€
{name}ãŒæ‰‹ãŒã‘ãŸã§ã‚ã‚ã†ã‚¯ã‚ªãƒªãƒ†ã‚£ã®ä½œå“ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        """.strip()
        
        return {
            'style_description': style_description,
            'work_examples': work_examples,
            'generation_prompt': generation_prompt
        }
    
    def get_persona(self, name: str) -> Optional[Dict]:
        """ãƒšãƒ«ã‚½ãƒŠå–å¾—"""
        return self.integrated_personas.get(name)
    
    def list_available_personas(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãƒšãƒ«ã‚½ãƒŠä¸€è¦§"""
        return list(self.integrated_personas.keys())

class AdvancedCopywriterAIGenerator:
    """é«˜ç²¾åº¦ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ AIç”Ÿæˆå™¨"""
    
    def __init__(self, persona_db: PersonaDatabase, api_key: str = None):
        self.persona_db = persona_db
        self.api_key = api_key
        
        # Claude APIåˆæœŸåŒ–
        if ANTHROPIC_AVAILABLE and api_key and api_key != "your-api-key-here":
            self.client = anthropic.Anthropic(api_key=api_key)
        else:
            self.client = None
            logging.warning("Claude API not available, using fallback generation")
    
    async def generate_advanced_copy(self, request: AdvancedCopywritingRequest) -> AdvancedCopywritingResult:
        """é«˜ç²¾åº¦ã‚³ãƒ”ãƒ¼ç”Ÿæˆ"""
        
        # ãƒšãƒ«ã‚½ãƒŠæƒ…å ±å–å¾—
        persona = self.persona_db.get_persona(request.copywriter_persona)
        if not persona:
            raise ValueError(f"Persona not found: {request.copywriter_persona}")
        
        # ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        generation_prompt = self.build_advanced_prompt(request, persona)
        
        # AIç”Ÿæˆå®Ÿè¡Œ
        if self.client:
            generated_content = await self.generate_with_claude(generation_prompt, request)
        else:
            generated_content = self.generate_fallback(request, persona)
        
        # å“è³ªåˆ†æ
        quality_scores = self.analyze_quality(generated_content, request, persona)
        
        # çµæœæ§‹ç¯‰
        return AdvancedCopywritingResult(
            primary_copy=generated_content['primary'],
            alternative_versions=generated_content.get('alternatives', []),
            style_accuracy_score=quality_scores['style_accuracy'],
            predicted_effectiveness=quality_scores['effectiveness'],
            readability_score=quality_scores['readability'],
            emotional_impact_score=quality_scores['emotional_impact'],
            style_elements_detected=quality_scores['detected_elements'],
            keyword_optimization=quality_scores['keyword_scores'],
            target_alignment=quality_scores['target_alignment'],
            generation_metadata=generated_content.get('metadata', {}),
            confidence_score=quality_scores['confidence'],
            recommended_usage=self.generate_usage_recommendations(quality_scores)
        )
    
    def build_advanced_prompt(self, request: AdvancedCopywritingRequest, persona: Dict) -> str:
        """é«˜åº¦ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        
        base_prompt = persona['generation_prompts']['generation_prompt']
        
        # è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        context_additions = f"""

å…·ä½“çš„ãªä¾é ¼å†…å®¹:
- å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹: {request.product_service}
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {request.target_audience}
- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—: {request.content_type}
- å¸Œæœ›ã™ã‚‹é•·ã•: {request.length_preference}
- ãƒˆãƒ¼ãƒ³: {request.tone_preference}
- ã‚¹ã‚¿ã‚¤ãƒ«å¼·åº¦: {request.style_intensity} (0.0-1.0)
- å‰µé€ æ€§ãƒ¬ãƒ™ãƒ«: {request.creativity_level} (0.0-1.0)

ã‚­ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {', '.join(request.key_messages)}
é¿ã‘ã‚‹ã¹ãè¨€è‘‰: {', '.join(request.avoid_words)}
        """
        
        if request.brand_guidelines:
            context_additions += f"\nãƒ–ãƒ©ãƒ³ãƒ‰ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³: {request.brand_guidelines}"
        
        if request.competitive_context:
            context_additions += f"\nç«¶åˆçŠ¶æ³: {request.competitive_context}"
        
        # å“è³ªè¦æ±‚
        quality_requirements = f"""

å“è³ªè¦æ±‚:
- {request.copywriter_persona}ã®ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‚’{request.style_intensity*100:.0f}%ã®å¼·åº¦ã§åæ˜ 
- å‰µé€ æ€§ãƒ¬ãƒ™ãƒ«{request.creativity_level*100:.0f}%ã§ã€ç‹¬å‰µçš„ã ãŒé©åˆ‡ãªè¡¨ç¾ã‚’ä½¿ç”¨
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã«æœ€é©åŒ–ã•ã‚ŒãŸè¨€è‘‰é¸ã³ã¨è¨´æ±‚
- {request.length_preference}ã®é•·ã•ã«é©ã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„

å‡ºåŠ›å½¢å¼:
1. ãƒ¡ã‚¤ãƒ³ã‚³ãƒ”ãƒ¼ï¼ˆæœ€ã‚‚æ¨å¥¨ã•ã‚Œã‚‹æ¡ˆï¼‰
2. ä»£æ›¿æ¡ˆ1ï¼ˆãƒˆãƒ¼ãƒ³ãŒç•°ãªã‚‹ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
3. ä»£æ›¿æ¡ˆ2ï¼ˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒç•°ãªã‚‹ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        """
        
        return base_prompt + context_additions + quality_requirements
    
    async def generate_with_claude(self, prompt: str, request: AdvancedCopywritingRequest) -> Dict:
        """Claude APIã§ã®ç”Ÿæˆ"""
        try:
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.messages.create(
                    model="claude-3-5-sonnet-20241022",
                    max_tokens=2000,
                    temperature=min(0.9, 0.3 + request.creativity_level * 0.6),
                    messages=[{"role": "user", "content": prompt}]
                )
            )
            
            content = response.content[0].text
            
            # ç”Ÿæˆå†…å®¹ã®è§£æãƒ»åˆ†å‰²
            lines = [line.strip() for line in content.split('\n') if line.strip()]
            
            primary = ""
            alternatives = []
            
            # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ”ãƒ¼ã¨ä»£æ›¿æ¡ˆã®åˆ†é›¢
            current_section = "main"
            for line in lines:
                if "ä»£æ›¿æ¡ˆ" in line or "ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³" in line:
                    current_section = "alt"
                elif line.startswith("1.") or line.startswith("ãƒ¡ã‚¤ãƒ³"):
                    current_section = "main"
                elif line.startswith("2.") or line.startswith("3."):
                    current_section = "alt"
                elif current_section == "main" and not line.startswith("ãƒ¡ã‚¤ãƒ³"):
                    primary += line + "\n"
                elif current_section == "alt" and not line.startswith(("2.", "3.", "ä»£æ›¿æ¡ˆ")):
                    if alternatives and line:
                        alternatives[-1] += line + "\n"
                    elif line:
                        alternatives.append(line + "\n")
            
            return {
                'primary': primary.strip(),
                'alternatives': [alt.strip() for alt in alternatives[:2]],
                'metadata': {
                    'model_used': 'claude-3-5-sonnet',
                    'temperature': min(0.9, 0.3 + request.creativity_level * 0.6),
                    'generated_at': datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            logging.error(f"Claude API generation failed: {e}")
            return self.generate_fallback(request, self.persona_db.get_persona(request.copywriter_persona))
    
    def generate_fallback(self, request: AdvancedCopywritingRequest, persona: Dict) -> Dict:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆï¼ˆAPIãªã—ï¼‰"""
        
        # ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´ã‹ã‚‰åŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ
        style_metrics = persona.get('style_metrics', {})
        work_samples = persona.get('work_samples', [])
        
        # åŸºæœ¬çš„ãªã‚³ãƒ”ãƒ¼æ§‹é€ 
        if request.length_preference == 'short':
            template = "{hook}ã€‚{product}ã§{benefit}ã€‚"
        elif request.length_preference == 'long':
            template = "{hook}ã€‚{problem}ã‚’è§£æ±ºã™ã‚‹{product}ã€‚{benefit_detail}ã€‚{call_to_action}ã€‚"
        else:
            template = "{hook}ã€‚{product}ãŒ{benefit}ã‚’ãŠå±Šã‘ã€‚"
        
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¦ç´ ã®ç”Ÿæˆ
        elements = {
            'hook': f"æ–°ã—ã„{request.target_audience}ã®ä½“é¨“",
            'product': request.product_service,
            'benefit': "ä¾¡å€¤ã‚ã‚‹æ™‚é–“",
            'problem': f"{request.target_audience}ã®èª²é¡Œ",
            'benefit_detail': "ã“ã‚Œã¾ã§ã«ãªã„æº€è¶³æ„Ÿ",
            'call_to_action': "ä»Šã™ãä½“é¨“ã—ã¦ãã ã•ã„"
        }
        
        # ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´
        if style_metrics.get('emotional_tone_score', 0) > 50:
            elements['hook'] = f"å¿ƒã‚’å‹•ã‹ã™{request.target_audience}ã¸ã®ææ¡ˆ"
        
        primary = template.format(**elements)
        
        # ä»£æ›¿æ¡ˆç”Ÿæˆ
        alternatives = [
            f"{request.product_service}ãŒã€{request.target_audience}ã®æ¯æ—¥ã‚’å¤‰ãˆã‚‹ã€‚",
            f"é¸ã°ã‚Œã‚‹ç†ç”±ãŒã‚ã‚‹ã€‚{request.product_service}ã¨ã„ã†é¸æŠã€‚"
        ]
        
        return {
            'primary': primary,
            'alternatives': alternatives,
            'metadata': {
                'generation_method': 'fallback',
                'generated_at': datetime.now().isoformat()
            }
        }
    
    def analyze_quality(self, content: Dict, request: AdvancedCopywritingRequest, persona: Dict) -> Dict:
        """å“è³ªåˆ†æ"""
        primary_copy = content['primary']
        
        # ã‚¹ã‚¿ã‚¤ãƒ«ä¸€è‡´åº¦
        style_accuracy = self.calculate_style_accuracy(primary_copy, persona)
        
        # åŠ¹æœäºˆæ¸¬
        effectiveness = self.predict_effectiveness(primary_copy, request)
        
        # èª­ã¿ã‚„ã™ã•
        readability = self.calculate_readability(primary_copy)
        
        # æ„Ÿæƒ…çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ
        emotional_impact = self.calculate_emotional_impact(primary_copy)
        
        # æ¤œå‡ºã•ã‚ŒãŸè¦ç´ 
        detected_elements = self.detect_style_elements(primary_copy, persona)
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€é©åŒ–
        keyword_scores = self.analyze_keyword_optimization(primary_copy, request)
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé©åˆåº¦
        target_alignment = self.analyze_target_alignment(primary_copy, request)
        
        # ç·åˆä¿¡é ¼åº¦
        confidence = (style_accuracy + effectiveness + readability) / 3
        
        return {
            'style_accuracy': style_accuracy,
            'effectiveness': effectiveness,
            'readability': readability,
            'emotional_impact': emotional_impact,
            'detected_elements': detected_elements,
            'keyword_scores': keyword_scores,
            'target_alignment': target_alignment,
            'confidence': confidence
        }
    
    def calculate_style_accuracy(self, copy_text: str, persona: Dict) -> float:
        """ã‚¹ã‚¿ã‚¤ãƒ«ä¸€è‡´åº¦è¨ˆç®—"""
        style_metrics = persona.get('style_metrics', {})
        
        # é•·ã•ã®ä¸€è‡´åº¦
        expected_length = style_metrics.get('avg_copy_length', 50)
        actual_length = len(copy_text)
        length_score = max(0, 100 - abs(expected_length - actual_length) / expected_length * 100)
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è‡´åº¦
        top_keywords = [kw[0] for kw in style_metrics.get('top_keywords', [])]
        keyword_matches = sum(1 for keyword in top_keywords if keyword in copy_text)
        keyword_score = (keyword_matches / len(top_keywords)) * 100 if top_keywords else 50
        
        # ç·åˆã‚¹ã‚³ã‚¢
        return (length_score * 0.3 + keyword_score * 0.7)
    
    def predict_effectiveness(self, copy_text: str, request: AdvancedCopywritingRequest) -> float:
        """åŠ¹æœäºˆæ¸¬"""
        score = 50.0  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
        
        # ã‚­ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åŒ…å«åº¦
        if request.key_messages:
            message_coverage = sum(1 for msg in request.key_messages if any(word in copy_text for word in msg.split()))
            score += (message_coverage / len(request.key_messages)) * 30
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé©åˆåº¦
        if request.target_audience in copy_text or any(word in copy_text for word in request.target_audience.split()):
            score += 10
        
        # ã‚³ãƒ¼ãƒ«ãƒ»ãƒˆã‚¥ãƒ»ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        cta_words = ['ä»Šã™ã', 'ãŠè©¦ã—', 'ä½“é¨“', 'ç™ºè¦‹', 'ã¯ã˜ã‚', 'é¸ã¶']
        if any(word in copy_text for word in cta_words):
            score += 10
        
        return min(100, score)
    
    def calculate_readability(self, copy_text: str) -> float:
        """èª­ã¿ã‚„ã™ã•è¨ˆç®—"""
        # ç°¡æ˜“èª­ã¿ã‚„ã™ã•æŒ‡æ¨™
        char_count = len(copy_text)
        sentence_count = len([s for s in re.split(r'[ã€‚ï¼ï¼Ÿ]', copy_text) if s.strip()])
        
        if sentence_count == 0:
            return 50.0
        
        avg_sentence_length = char_count / sentence_count
        
        # ç†æƒ³çš„ãªæ–‡é•·ï¼ˆ20-40æ–‡å­—ï¼‰ã‹ã‚‰ã®ä¹–é›¢åº¦ã§è©•ä¾¡
        readability = max(0, 100 - abs(30 - avg_sentence_length) * 2)
        
        return readability
    
    def calculate_emotional_impact(self, copy_text: str) -> float:
        """æ„Ÿæƒ…çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆè¨ˆç®—"""
        emotional_words = [
            'æ„Ÿå‹•', 'é©šã', 'å–œã³', 'æ„›', 'å¹¸ã›', 'ç´ æ™´ã‚‰ã—ã„', 'ç¾ã—ã„', 'ç‰¹åˆ¥',
            'æ„Ÿè¬', 'å¿ƒ', 'æ€ã„', 'é¡˜ã„', 'å¤¢', 'å¸Œæœ›', 'æ„Ÿã˜ã‚‹', 'ä½“é¨“'
        ]
        
        impact_count = sum(1 for word in emotional_words if word in copy_text)
        return min(100, impact_count * 20)
    
    def detect_style_elements(self, copy_text: str, persona: Dict) -> List[str]:
        """ã‚¹ã‚¿ã‚¤ãƒ«è¦ç´ æ¤œå‡º"""
        elements = []
        
        # ã‚·ã‚°ãƒãƒãƒ£ãƒ¼è¦ç´ ãƒã‚§ãƒƒã‚¯
        signature_elements = persona.get('signature_elements', [])
        for element in signature_elements:
            if 'èªå½™' in element and len(set(copy_text.split())) > 5:
                elements.append('èªå½™å¤šæ§˜æ€§')
            elif 'æ„Ÿæƒ…' in element and any(word in copy_text for word in ['æ„Ÿã˜', 'å¿ƒ', 'æ€ã„']):
                elements.append('æ„Ÿæƒ…çš„è¡¨ç¾')
            elif 'èª­ã¿ã‚„ã™ã•' in element and len(copy_text) < 100:
                elements.append('ç°¡æ½”ãªè¡¨ç¾')
        
        return elements
    
    def analyze_keyword_optimization(self, copy_text: str, request: AdvancedCopywritingRequest) -> Dict[str, float]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€é©åŒ–åˆ†æ"""
        scores = {}
        
        # å•†å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹åã®å«æœ‰
        if request.product_service.lower() in copy_text.lower():
            scores['product_inclusion'] = 100.0
        else:
            scores['product_inclusion'] = 0.0
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé©åˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        target_words = request.target_audience.split()
        target_matches = sum(1 for word in target_words if word in copy_text)
        scores['target_relevance'] = (target_matches / len(target_words)) * 100 if target_words else 0
        
        return scores
    
    def analyze_target_alignment(self, copy_text: str, request: AdvancedCopywritingRequest) -> Dict[str, float]:
        """ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé©åˆåº¦åˆ†æ"""
        alignment = {}
        
        # å¹´ä»£é©åˆåº¦ï¼ˆç°¡æ˜“åˆ¤å®šï¼‰
        if 'è‹¥ã„' in request.target_audience or '20ä»£' in request.target_audience:
            youth_words = ['æ–°ã—ã„', 'ãƒˆãƒ¬ãƒ³ãƒ‰', 'ã‚¹ã‚¿ã‚¤ãƒªãƒƒã‚·ãƒ¥', 'ä»Š', 'æœ€æ–°']
            alignment['age_appropriateness'] = sum(10 for word in youth_words if word in copy_text)
        else:
            mature_words = ['ä¿¡é ¼', 'å“è³ª', 'å®‰å¿ƒ', 'å®Ÿç¸¾', 'çµŒé¨“']
            alignment['age_appropriateness'] = sum(10 for word in mature_words if word in copy_text)
        
        # æ€§åˆ¥é©åˆåº¦
        if 'å¥³æ€§' in request.target_audience:
            female_words = ['ç¾ã—ã„', 'å„ªã—ã„', 'ã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆ', 'ã‹ã‚ã„ã„', 'ãŠã—ã‚ƒã‚Œ']
            alignment['gender_appropriateness'] = sum(10 for word in female_words if word in copy_text)
        elif 'ç”·æ€§' in request.target_audience:
            male_words = ['åŠ›å¼·ã„', 'ã‚¯ãƒ¼ãƒ«', 'ã‚¹ãƒãƒ¼ãƒˆ', 'ãƒ—ãƒ­', 'æœ¬æ ¼']
            alignment['gender_appropriateness'] = sum(10 for word in male_words if word in copy_text)
        else:
            alignment['gender_appropriateness'] = 50.0
        
        return alignment
    
    def generate_usage_recommendations(self, quality_scores: Dict) -> List[str]:
        """ä½¿ç”¨æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        if quality_scores['style_accuracy'] > 80:
            recommendations.append("ã‚¹ã‚¿ã‚¤ãƒ«å†ç¾åº¦ãŒé«˜ãã€ãƒ¡ã‚¤ãƒ³ã‚³ãƒ”ãƒ¼ã¨ã—ã¦ä½¿ç”¨æ¨å¥¨")
        
        if quality_scores['effectiveness'] > 75:
            recommendations.append("é«˜ã„åŠ¹æœãŒæœŸå¾…ã§ãã€å®Ÿéš›ã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã§ä½¿ç”¨å¯èƒ½")
        
        if quality_scores['readability'] > 70:
            recommendations.append("èª­ã¿ã‚„ã™ãã€å¹…åºƒã„å±¤ã«è¨´æ±‚å¯èƒ½")
        
        if quality_scores['emotional_impact'] > 60:
            recommendations.append("æ„Ÿæƒ…çš„è¨´æ±‚åŠ›ãŒã‚ã‚Šã€ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ç”¨é€”ã«é©ã—ã¦ã„ã‚‹")
        
        if not recommendations:
            recommendations.append("å“è³ªå‘ä¸Šã®ãŸã‚å†ç”Ÿæˆã‚’æ¨å¥¨")
        
        return recommendations

# çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹
class ProductionCopywriterAI:
    """æœ¬æ ¼é‹ç”¨ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼AIã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path: str, analysis_path: str, api_key: str = None):
        self.persona_db = PersonaDatabase(db_path, analysis_path)
        self.generator = AdvancedCopywriterAIGenerator(self.persona_db, api_key)
        
        logging.info("Production Copywriter AI System initialized")
    
    async def create_professional_copy(self, 
                                     copywriter_name: str,
                                     product_service: str,
                                     target_audience: str,
                                     content_type: str = "advertisement",
                                     **kwargs) -> AdvancedCopywritingResult:
        """ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚³ãƒ”ãƒ¼ä½œæˆ"""
        
        request = AdvancedCopywritingRequest(
            copywriter_persona=copywriter_name,
            content_type=content_type,
            product_service=product_service,
            target_audience=target_audience,
            style_intensity=kwargs.get('style_intensity', 0.8),
            creativity_level=kwargs.get('creativity_level', 0.7),
            length_preference=kwargs.get('length_preference', 'medium'),
            tone_preference=kwargs.get('tone_preference', 'professional'),
            key_messages=kwargs.get('key_messages', []),
            avoid_words=kwargs.get('avoid_words', []),
            target_metrics=kwargs.get('target_metrics'),
            brand_guidelines=kwargs.get('brand_guidelines'),
            competitive_context=kwargs.get('competitive_context'),
            cultural_considerations=kwargs.get('cultural_considerations')
        )
        
        return await self.generator.generate_advanced_copy(request)
    
    def get_available_copywriters(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼å–å¾—"""
        return self.persona_db.list_available_personas()
    
    def get_copywriter_profile(self, name: str) -> Optional[Dict]:
        """ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—"""
        return self.persona_db.get_persona(name)

# ãƒ‡ãƒ¢ãƒ»ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
async def run_production_demo():
    """æœ¬æ ¼ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    print("=== Production Copywriter AI System Demo ===\n")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = ProductionCopywriterAI(
        db_path='/Users/naoki/tcc_copyworks.db',
        analysis_path='/Users/naoki/copywriter_style_analysis_20250810_000147.json'
    )
    
    print("ğŸ“‹ Available Copywriters:")
    available = system.get_available_copywriters()
    for i, name in enumerate(available, 1):
        print(f"  {i}. {name}")
    
    if not available:
        print("  No copywriters available in database")
        return
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®Ÿè¡Œ
    test_copywriter = available[0]
    print(f"\nğŸ¯ Testing with: {test_copywriter}")
    
    # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«è¡¨ç¤º
    profile = system.get_copywriter_profile(test_copywriter)
    if profile:
        print(f"  Profile loaded: {len(profile.get('work_samples', []))} work samples available")
        print(f"  Style metrics: {list(profile.get('style_metrics', {}).keys())[:5]}")
    
    # ã‚³ãƒ”ãƒ¼ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    print("\nğŸš€ Generating professional copy...")
    
    result = await system.create_professional_copy(
        copywriter_name=test_copywriter,
        product_service="ãƒ—ãƒ¬ãƒŸã‚¢ãƒ æ—¥æœ¬èŒ¶",
        target_audience="30-50ä»£ã®å“è³ªé‡è¦–å±¤",
        content_type="é›‘èªŒåºƒå‘Š",
        style_intensity=0.9,
        creativity_level=0.8,
        key_messages=["ä¼çµ±ã®æŠ€è¡“", "æœ€é«˜å“è³ª", "æ—¥æœ¬ã®å¿ƒ"],
        length_preference="medium"
    )
    
    # çµæœè¡¨ç¤º
    print(f"\nâœ¨ Generated Copy:")
    print(f"Primary: {result.primary_copy}")
    
    if result.alternative_versions:
        print(f"\nAlternatives:")
        for i, alt in enumerate(result.alternative_versions, 1):
            print(f"  {i}. {alt}")
    
    print(f"\nğŸ“Š Quality Scores:")
    print(f"  Style Accuracy: {result.style_accuracy_score:.1f}%")
    print(f"  Predicted Effectiveness: {result.predicted_effectiveness:.1f}%")
    print(f"  Readability: {result.readability_score:.1f}")
    print(f"  Emotional Impact: {result.emotional_impact_score:.1f}")
    print(f"  Confidence: {result.confidence_score:.1f}%")
    
    print(f"\nğŸ’¡ Recommendations:")
    for rec in result.recommended_usage:
        print(f"  â€¢ {rec}")
    
    print(f"\nâœ… Production demo completed!")
    return result

if __name__ == "__main__":
    # æœ¬æ ¼ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¢å®Ÿè¡Œ
    demo_result = asyncio.run(run_production_demo())