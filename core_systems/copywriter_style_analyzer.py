"""
Advanced Copywriter Style Analysis System
é«˜åº¦ãªã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æã‚·ã‚¹ãƒ†ãƒ 

å®Ÿéš›ã®ä½œå“ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’
å®šé‡çš„ãƒ»å®šæ€§çš„ã«åˆ†æã—ã€AIãƒšãƒ«ã‚½ãƒŠç”Ÿæˆã«æ´»ç”¨
"""

import json
import re
import sqlite3
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict
from collections import Counter, defaultdict
import unicodedata
from datetime import datetime

# æ—¥æœ¬èªå½¢æ…‹ç´ è§£æç”¨ï¼ˆMeCabãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ€ãƒŸãƒ¼å®Ÿè£…ã‚‚å«ã‚€ï¼‰
try:
    import MeCab
    MECAB_AVAILABLE = True
except ImportError:
    MECAB_AVAILABLE = False
    print("MeCab not available, using simplified analysis")

# MeCabã‚¯ãƒ©ã‚¹å®šç¾©ï¼ˆimportã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
if not MECAB_AVAILABLE:
    class MeCab:
        @staticmethod
        def Tagger(option):
            return None

@dataclass
class StyleMetrics:
    """ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡æ¨™"""
    copywriter_name: str
    
    # åŸºæœ¬çµ±è¨ˆ
    total_works: int
    avg_copy_length: float
    median_copy_length: float
    
    # è¨€èªç‰¹å¾´
    vocabulary_richness: float  # èªå½™ã®è±Šå¯Œã•
    readability_score: float    # èª­ã¿ã‚„ã™ã•ã‚¹ã‚³ã‚¢
    emotional_tone_score: float # æ„Ÿæƒ…çš„ãƒˆãƒ¼ãƒ³
    
    # æ§‹é€ ç‰¹å¾´
    avg_sentences_per_copy: float
    punctuation_frequency: Dict[str, float]
    
    # å†…å®¹ç‰¹å¾´
    top_keywords: List[Tuple[str, int]]
    common_themes: List[str]
    industry_specialization: Dict[str, int]
    media_preference: Dict[str, int]
    
    # æ™‚ç³»åˆ—ç‰¹å¾´
    career_evolution: List[Dict]
    active_period: Tuple[int, int]
    
    # ç‹¬è‡ªæ€§æŒ‡æ¨™
    uniqueness_score: float
    signature_phrases: List[str]

@dataclass
class CopyAnalysis:
    """å€‹åˆ¥ã‚³ãƒ”ãƒ¼ä½œå“ã®åˆ†æçµæœ"""
    entry_id: str
    copy_text: str
    copywriter: str
    
    # åŸºæœ¬æŒ‡æ¨™
    length: int
    sentence_count: int
    word_count: int
    
    # è¨€èªåˆ†æ
    pos_distribution: Dict[str, int]  # å“è©åˆ†å¸ƒ
    keywords: List[str]
    emotional_words: List[str]
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ç‰¹å¾´
    tone: str  # 'formal', 'casual', 'emotional', 'rational'
    target_appeal: str  # 'logical', 'emotional', 'lifestyle'
    complexity: str  # 'simple', 'moderate', 'complex'

class CopywriterStyleAnalyzer:
    """ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æå™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.mecab = None
        
        # MeCabåˆæœŸåŒ–
        if MECAB_AVAILABLE:
            try:
                self.mecab = MeCab.Tagger('-Owakati')
                print("MeCab initialized successfully")
            except:
                print("MeCab initialization failed, using fallback")
        
        # æ„Ÿæƒ…èªè¾æ›¸ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        self.emotional_words = {
            'positive': ['ç¾ã—ã„', 'ç´ æ™´ã‚‰ã—ã„', 'æ¥½ã—ã„', 'å¬‰ã—ã„', 'æ„›', 'å¹¸ã›', 'å–œã³', 'æ„Ÿå‹•', 'ç´ æ•µ', 'æœ€é«˜'],
            'negative': ['æ‚²ã—ã„', 'è¾›ã„', 'å›°é›£', 'å•é¡Œ', 'ä¸å®‰', 'å¿ƒé…', 'è‹¦ã—ã„', 'å¤±æœ›'],
            'neutral': ['æ™®é€š', 'ä¸€èˆ¬', 'æ¨™æº–', 'é€šå¸¸', 'å¹³å‡']
        }
        
        # æ¥­ç•Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸
        self.industry_keywords = {
            'é£Ÿå“ãƒ»é£²æ–™': ['ç¾å‘³ã—ã„', 'å‘³', 'é£Ÿã¹ã‚‹', 'é£²ã‚€', 'æ–™ç†', 'ã‚°ãƒ«ãƒ¡', 'æ–°é®®', 'æ „é¤Š'],
            'ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³': ['ç€ã‚‹', 'ã‚¹ã‚¿ã‚¤ãƒ«', 'ãŠã—ã‚ƒã‚Œ', 'ãƒˆãƒ¬ãƒ³ãƒ‰', 'ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆ', 'ãƒ–ãƒ©ãƒ³ãƒ‰'],
            'è‡ªå‹•è»Š': ['èµ°ã‚‹', 'ãƒ‰ãƒ©ã‚¤ãƒ–', 'è»Š', 'ã‚¨ãƒ³ã‚¸ãƒ³', 'ç‡ƒè²»', 'å®‰å…¨', 'æ€§èƒ½'],
            'åŒ–ç²§å“': ['ç¾ã—ã•', 'ç¾å®¹', 'ã‚¹ã‚­ãƒ³ã‚±ã‚¢', 'è‚Œ', 'ãƒ¡ã‚¤ã‚¯', 'è‹¥ã€…ã—ã„'],
            'ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼': ['é©æ–°', 'æŠ€è¡“', 'ãƒ‡ã‚¸ã‚¿ãƒ«', 'AI', 'æœªæ¥', 'åŠ¹ç‡', 'ä¾¿åˆ©']
        }
        
        print("CopywriterStyleAnalyzer initialized")
    
    def load_copyworks_data(self) -> List[Dict]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã‚³ãƒ”ãƒ¼ä½œå“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT entry_id, copy_text, copywriter, client, industry, 
                       media_type, year, award
                FROM copy_works 
                WHERE copy_text IS NOT NULL AND copy_text != ""
                ORDER BY copywriter, year
            ''')
            
            works = []
            for row in cursor.fetchall():
                works.append({
                    'entry_id': row[0],
                    'copy_text': row[1],
                    'copywriter': row[2],
                    'client': row[3],
                    'industry': row[4],
                    'media_type': row[5],
                    'year': row[6],
                    'award': row[7]
                })
            
            conn.close()
            print(f"Loaded {len(works)} copy works")
            return works
            
        except Exception as e:
            print(f"Error loading data: {e}")
            return []
    
    def analyze_single_copy(self, copy_data: Dict) -> CopyAnalysis:
        """å€‹åˆ¥ã‚³ãƒ”ãƒ¼ä½œå“ã®è©³ç´°åˆ†æ"""
        text = copy_data['copy_text']
        
        # åŸºæœ¬çµ±è¨ˆ
        length = len(text)
        sentence_count = len([s for s in re.split(r'[ã€‚ï¼ï¼Ÿ]', text) if s.strip()])
        
        # å½¢æ…‹ç´ è§£æ
        if self.mecab and MECAB_AVAILABLE:
            words = self.mecab.parse(text).strip().split()
            word_count = len(words)
            # ã‚ˆã‚Šè©³ç´°ãªå“è©åˆ†æã‚‚å¯èƒ½
            pos_distribution = self._analyze_pos_distribution(text)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“å˜èªåˆ†å‰²
            words = re.findall(r'[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾ ]+', text)
            word_count = len(words)
            pos_distribution = {}
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        keywords = self._extract_keywords(text, words)
        
        # æ„Ÿæƒ…èªæŠ½å‡º
        emotional_words = self._extract_emotional_words(text)
        
        # ãƒˆãƒ¼ãƒ³åˆ¤å®š
        tone = self._classify_tone(text, emotional_words)
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨´æ±‚åˆ¤å®š
        target_appeal = self._classify_target_appeal(text)
        
        # è¤‡é›‘ã•åˆ¤å®š
        complexity = self._classify_complexity(length, sentence_count, word_count)
        
        return CopyAnalysis(
            entry_id=copy_data['entry_id'],
            copy_text=text,
            copywriter=copy_data['copywriter'],
            length=length,
            sentence_count=sentence_count,
            word_count=word_count,
            pos_distribution=pos_distribution,
            keywords=keywords,
            emotional_words=emotional_words,
            tone=tone,
            target_appeal=target_appeal,
            complexity=complexity
        )
    
    def _analyze_pos_distribution(self, text: str) -> Dict[str, int]:
        """å“è©åˆ†å¸ƒåˆ†æï¼ˆMeCabä½¿ç”¨ï¼‰"""
        if not self.mecab:
            return {}
        
        try:
            # è©³ç´°ãªå“è©åˆ†æã®å®Ÿè£…
            # å®Ÿéš›ã«ã¯MeCabã®å½¢æ…‹ç´ è§£æçµæœã‹ã‚‰å“è©ã‚’æŠ½å‡º
            return {'noun': 0, 'verb': 0, 'adjective': 0, 'particle': 0}
        except:
            return {}
    
    def _extract_keywords(self, text: str, words: List[str]) -> List[str]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        # TF-IDFçš„ãªæ‰‹æ³•ã§é‡è¦èªã‚’æŠ½å‡ºï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        word_freq = Counter(words)
        # é »åº¦ä¸Šä½ã‹ã¤æ„å‘³ã®ã‚ã‚‹èªã‚’é¸æŠ
        keywords = [word for word, freq in word_freq.most_common(5) 
                   if len(word) > 1 and not re.match(r'^[ã-ã‚“]*$', word)]
        return keywords[:3]
    
    def _extract_emotional_words(self, text: str) -> List[str]:
        """æ„Ÿæƒ…èªæŠ½å‡º"""
        emotional = []
        for category, words in self.emotional_words.items():
            for word in words:
                if word in text:
                    emotional.append(f"{word}({category})")
        return emotional
    
    def _classify_tone(self, text: str, emotional_words: List[str]) -> str:
        """ãƒˆãƒ¼ãƒ³åˆ†é¡"""
        if len(emotional_words) > 2:
            return 'emotional'
        elif 'ã€‚' in text and 'ï¼' not in text and 'ï¼Ÿ' not in text:
            return 'formal'
        elif 'ï¼' in text or 'ã ' in text or 'ã§ã‚ã‚‹' in text:
            return 'assertive'
        else:
            return 'casual'
    
    def _classify_target_appeal(self, text: str) -> str:
        """è¨´æ±‚ã‚¿ã‚¤ãƒ—åˆ†é¡"""
        logical_indicators = ['åŠ¹æœ', 'çµæœ', 'å®Ÿè¨¼', 'ç§‘å­¦', 'ç ”ç©¶', 'ãƒ‡ãƒ¼ã‚¿']
        emotional_indicators = ['æ„Ÿã˜', 'ä½“é¨“', 'æ°—æŒã¡', 'å¿ƒ', 'æ„›', 'å¹¸ã›']
        lifestyle_indicators = ['ç”Ÿæ´»', 'æ—¥å¸¸', 'ãƒ©ã‚¤ãƒ•', 'ã‚¹ã‚¿ã‚¤ãƒ«', 'æš®ã‚‰ã—']
        
        logical_score = sum(1 for word in logical_indicators if word in text)
        emotional_score = sum(1 for word in emotional_indicators if word in text)
        lifestyle_score = sum(1 for word in lifestyle_indicators if word in text)
        
        if logical_score >= emotional_score and logical_score >= lifestyle_score:
            return 'logical'
        elif emotional_score >= lifestyle_score:
            return 'emotional'
        else:
            return 'lifestyle'
    
    def _classify_complexity(self, length: int, sentence_count: int, word_count: int) -> str:
        """è¤‡é›‘ã•åˆ†é¡"""
        if length < 20 and sentence_count <= 1:
            return 'simple'
        elif length < 100 and sentence_count <= 3:
            return 'moderate'
        else:
            return 'complex'
    
    def analyze_copywriter_style(self, copywriter_name: str, works: List[Dict]) -> StyleMetrics:
        """ç‰¹å®šã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã®ç·åˆã‚¹ã‚¿ã‚¤ãƒ«åˆ†æ"""
        copywriter_works = [w for w in works if w['copywriter'] == copywriter_name]
        
        if not copywriter_works:
            return None
        
        # å€‹åˆ¥ã‚³ãƒ”ãƒ¼åˆ†æ
        copy_analyses = [self.analyze_single_copy(work) for work in copywriter_works]
        
        # åŸºæœ¬çµ±è¨ˆè¨ˆç®—
        lengths = [analysis.length for analysis in copy_analyses]
        total_works = len(copywriter_works)
        avg_length = np.mean(lengths) if lengths else 0
        median_length = np.median(lengths) if lengths else 0
        
        # èªå½™ã®è±Šå¯Œã•è¨ˆç®—
        all_keywords = []
        for analysis in copy_analyses:
            all_keywords.extend(analysis.keywords)
        vocabulary_richness = len(set(all_keywords)) / len(all_keywords) if all_keywords else 0
        
        # èª­ã¿ã‚„ã™ã•ã‚¹ã‚³ã‚¢ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        avg_sentences = np.mean([a.sentence_count for a in copy_analyses]) if copy_analyses else 0
        readability_score = max(0, 100 - avg_length/10 - avg_sentences*5)
        
        # æ„Ÿæƒ…çš„ãƒˆãƒ¼ãƒ³
        emotional_copies = sum(1 for a in copy_analyses if len(a.emotional_words) > 0)
        emotional_tone_score = (emotional_copies / total_works) * 100 if total_works > 0 else 0
        
        # å¥èª­ç‚¹é »åº¦
        punctuation_freq = self._calculate_punctuation_frequency(copywriter_works)
        
        # ãƒˆãƒƒãƒ—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        keyword_counter = Counter()
        for analysis in copy_analyses:
            keyword_counter.update(analysis.keywords)
        top_keywords = keyword_counter.most_common(10)
        
        # ãƒ†ãƒ¼ãƒåˆ†æ
        common_themes = self._extract_common_themes(copy_analyses)
        
        # æ¥­ç•Œç‰¹åŒ–åº¦
        industry_dist = Counter(work['industry'] for work in copywriter_works if work['industry'])
        
        # ãƒ¡ãƒ‡ã‚£ã‚¢é¸å¥½
        media_dist = Counter(work['media_type'] for work in copywriter_works if work['media_type'])
        
        # ã‚­ãƒ£ãƒªã‚¢é€²åŒ–
        career_evolution = self._analyze_career_evolution(copywriter_works)
        
        # æ´»å‹•æœŸé–“
        years = [work['year'] for work in copywriter_works if work['year']]
        active_period = (min(years), max(years)) if years else (0, 0)
        
        # ç‹¬è‡ªæ€§ã‚¹ã‚³ã‚¢
        uniqueness_score = self._calculate_uniqueness_score(copywriter_name, copy_analyses, works)
        
        # ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚º
        signature_phrases = self._extract_signature_phrases(copy_analyses)
        
        return StyleMetrics(
            copywriter_name=copywriter_name,
            total_works=total_works,
            avg_copy_length=avg_length,
            median_copy_length=median_length,
            vocabulary_richness=vocabulary_richness,
            readability_score=readability_score,
            emotional_tone_score=emotional_tone_score,
            avg_sentences_per_copy=avg_sentences,
            punctuation_frequency=punctuation_freq,
            top_keywords=top_keywords,
            common_themes=common_themes,
            industry_specialization=dict(industry_dist),
            media_preference=dict(media_dist),
            career_evolution=career_evolution,
            active_period=active_period,
            uniqueness_score=uniqueness_score,
            signature_phrases=signature_phrases
        )
    
    def _calculate_punctuation_frequency(self, works: List[Dict]) -> Dict[str, float]:
        """å¥èª­ç‚¹ä½¿ç”¨é »åº¦è¨ˆç®—"""
        punctuation_marks = {'ã€‚': 0, 'ã€': 0, 'ï¼': 0, 'ï¼Ÿ': 0, 'ã€œ': 0}
        total_chars = 0
        
        for work in works:
            text = work['copy_text']
            total_chars += len(text)
            for mark in punctuation_marks:
                punctuation_marks[mark] += text.count(mark)
        
        # 100æ–‡å­—ã‚ãŸã‚Šã®å‡ºç¾é »åº¦
        return {mark: (count / total_chars * 100) if total_chars > 0 else 0 
                for mark, count in punctuation_marks.items()}
    
    def _extract_common_themes(self, analyses: List[CopyAnalysis]) -> List[str]:
        """å…±é€šãƒ†ãƒ¼ãƒæŠ½å‡º"""
        # è¨´æ±‚ã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒã‹ã‚‰ä¸»è¦ãƒ†ãƒ¼ãƒã‚’åˆ¤å®š
        appeal_counter = Counter(analysis.target_appeal for analysis in analyses)
        tone_counter = Counter(analysis.tone for analysis in analyses)
        
        themes = []
        if appeal_counter.most_common(1):
            themes.append(f"ä¸»è¦è¨´æ±‚: {appeal_counter.most_common(1)[0][0]}")
        if tone_counter.most_common(1):
            themes.append(f"åŸºèª¿ãƒˆãƒ¼ãƒ³: {tone_counter.most_common(1)[0][0]}")
        
        return themes
    
    def _analyze_career_evolution(self, works: List[Dict]) -> List[Dict]:
        """ã‚­ãƒ£ãƒªã‚¢é€²åŒ–åˆ†æ"""
        # å¹´ä»£åˆ¥ã®ä½œå“å‚¾å‘å¤‰åŒ–ã‚’åˆ†æ
        year_groups = defaultdict(list)
        for work in works:
            if work['year']:
                decade = (work['year'] // 10) * 10
                year_groups[decade].append(work)
        
        evolution = []
        for decade, decade_works in sorted(year_groups.items()):
            avg_length = np.mean([len(work['copy_text']) for work in decade_works])
            evolution.append({
                'period': f"{decade}å¹´ä»£",
                'works_count': len(decade_works),
                'avg_length': avg_length,
                'themes': list(set(work['industry'] for work in decade_works if work['industry']))[:3]
            })
        
        return evolution
    
    def _calculate_uniqueness_score(self, copywriter_name: str, analyses: List[CopyAnalysis], all_works: List[Dict]) -> float:
        """ç‹¬è‡ªæ€§ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        # ä»–ã®ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã¨ã®å·®ç•°åŒ–åº¦ã‚’æ¸¬å®š
        copywriter_keywords = set()
        for analysis in analyses:
            copywriter_keywords.update(analysis.keywords)
        
        # ä»–ã®ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åé›†
        other_keywords = set()
        for work in all_works:
            if work['copywriter'] != copywriter_name:
                # ç°¡æ˜“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
                words = re.findall(r'[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾ ]+', work['copy_text'])
                word_freq = Counter(words)
                keywords = [word for word, freq in word_freq.most_common(3) if len(word) > 1]
                other_keywords.update(keywords)
        
        # Jaccardä¿‚æ•°ã®é€†æ•°ï¼ˆç‹¬è‡ªæ€§ã®æŒ‡æ¨™ï¼‰
        if not copywriter_keywords or not other_keywords:
            return 50.0
        
        intersection = len(copywriter_keywords & other_keywords)
        union = len(copywriter_keywords | other_keywords)
        jaccard = intersection / union if union > 0 else 0
        uniqueness = (1 - jaccard) * 100
        
        return uniqueness
    
    def _extract_signature_phrases(self, analyses: List[CopyAnalysis]) -> List[str]:
        """ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡º"""
        # é »å‡ºã™ã‚‹ç‰¹å¾´çš„ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æŠ½å‡º
        all_text = ' '.join(analysis.copy_text for analysis in analyses)
        
        # 2-3æ–‡å­—ã®é »å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ç´¢
        phrases = []
        for length in [2, 3, 4]:
            for i in range(len(all_text) - length + 1):
                phrase = all_text[i:i+length]
                if re.match(r'^[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾ ]+$', phrase) and all_text.count(phrase) >= 2:
                    phrases.append(phrase)
        
        # é »åº¦ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚’è¿”ã™
        phrase_counter = Counter(phrases)
        return [phrase for phrase, count in phrase_counter.most_common(5)]
    
    def generate_comprehensive_report(self) -> Dict:
        """åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        works = self.load_copyworks_data()
        if not works:
            return {"error": "No data available"}
        
        # å…¨ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã®åˆ†æ
        copywriters = list(set(work['copywriter'] for work in works))
        style_metrics = {}
        
        print(f"Analyzing {len(copywriters)} copywriters...")
        
        for copywriter in copywriters:
            print(f"Analyzing: {copywriter}")
            metrics = self.analyze_copywriter_style(copywriter, works)
            if metrics:
                style_metrics[copywriter] = asdict(metrics)
        
        # å…¨ä½“çµ±è¨ˆ
        overall_stats = {
            'total_copywriters': len(copywriters),
            'total_works': len(works),
            'analysis_date': datetime.now().isoformat(),
            'avg_works_per_copywriter': len(works) / len(copywriters) if copywriters else 0
        }
        
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆ
        rankings = self._generate_rankings(style_metrics)
        
        return {
            'overall_statistics': overall_stats,
            'copywriter_analyses': style_metrics,
            'rankings': rankings,
            'methodology': self._get_methodology_description()
        }
    
    def _generate_rankings(self, style_metrics: Dict) -> Dict:
        """å„ç¨®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆ"""
        rankings = {}
        
        # èªå½™è±Šå¯Œåº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        vocab_ranking = sorted(
            [(name, data['vocabulary_richness']) for name, data in style_metrics.items()],
            key=lambda x: x[1], reverse=True
        )
        rankings['vocabulary_richness'] = vocab_ranking[:10]
        
        # æ„Ÿæƒ…è¡¨ç¾åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        emotion_ranking = sorted(
            [(name, data['emotional_tone_score']) for name, data in style_metrics.items()],
            key=lambda x: x[1], reverse=True
        )
        rankings['emotional_tone'] = emotion_ranking[:10]
        
        # ç‹¬è‡ªæ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        unique_ranking = sorted(
            [(name, data['uniqueness_score']) for name, data in style_metrics.items()],
            key=lambda x: x[1], reverse=True
        )
        rankings['uniqueness'] = unique_ranking[:10]
        
        # ä½œå“æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        works_ranking = sorted(
            [(name, data['total_works']) for name, data in style_metrics.items()],
            key=lambda x: x[1], reverse=True
        )
        rankings['productivity'] = works_ranking[:10]
        
        return rankings
    
    def _get_methodology_description(self) -> Dict:
        """åˆ†ææ‰‹æ³•èª¬æ˜"""
        return {
            'vocabulary_richness': 'ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•° / ç·ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°',
            'readability_score': '100 - å¹³å‡æ–‡å­—æ•°/10 - å¹³å‡æ–‡æ•°*5',
            'emotional_tone_score': 'æ„Ÿæƒ…èªã‚’å«ã‚€ä½œå“ã®å‰²åˆ * 100',
            'uniqueness_score': '(1 - ä»–ä½œè€…ã¨ã®å…±é€šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç‡) * 100',
            'limitations': [
                'ã‚µãƒ³ãƒ—ãƒ«æ•°ã«ã‚ˆã‚‹ç²¾åº¦ã®åˆ¶ç´„',
                'å½¢æ…‹ç´ è§£æã®ç²¾åº¦ä¾å­˜',
                'æ¥­ç•Œãƒ»æ™‚ä»£èƒŒæ™¯ã®è€ƒæ…®ä¸è¶³'
            ]
        }
    
    def export_analysis_results(self, report: Dict, filename: str = None):
        """åˆ†æçµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if filename is None:
            filename = f"/Users/naoki/copywriter_style_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"Analysis results exported to: {filename}")
        return filename

# ãƒ‡ãƒ¢å®Ÿè¡Œ
def run_style_analysis_demo():
    """ã‚¹ã‚¿ã‚¤ãƒ«åˆ†æãƒ‡ãƒ¢å®Ÿè¡Œ"""
    print("=== Copywriter Style Analysis Demo ===\n")
    
    analyzer = CopywriterStyleAnalyzer('/Users/naoki/tcc_copyworks.db')
    
    # åŒ…æ‹¬çš„åˆ†æå®Ÿè¡Œ
    report = analyzer.generate_comprehensive_report()
    
    if 'error' in report:
        print(f"Error: {report['error']}")
        return
    
    # çµæœè¡¨ç¤º
    print("ğŸ“Š Analysis Results Summary:")
    print(f"  Total Copywriters Analyzed: {report['overall_statistics']['total_copywriters']}")
    print(f"  Total Works Analyzed: {report['overall_statistics']['total_works']}")
    print(f"  Avg Works per Copywriter: {report['overall_statistics']['avg_works_per_copywriter']:.1f}")
    
    print("\nğŸ† Top Rankings:")
    
    if 'vocabulary_richness' in report['rankings']:
        print("\n  èªå½™è±Šå¯Œåº¦ TOP3:")
        for i, (name, score) in enumerate(report['rankings']['vocabulary_richness'][:3], 1):
            print(f"    {i}. {name}: {score:.3f}")
    
    if 'emotional_tone' in report['rankings']:
        print("\n  æ„Ÿæƒ…è¡¨ç¾åº¦ TOP3:")
        for i, (name, score) in enumerate(report['rankings']['emotional_tone'][:3], 1):
            print(f"    {i}. {name}: {score:.1f}%")
    
    if 'uniqueness' in report['rankings']:
        print("\n  ç‹¬è‡ªæ€§ã‚¹ã‚³ã‚¢ TOP3:")
        for i, (name, score) in enumerate(report['rankings']['uniqueness'][:3], 1):
            print(f"    {i}. {name}: {score:.1f}")
    
    # è©³ç´°åˆ†æä¾‹
    if report['copywriter_analyses']:
        sample_writer = list(report['copywriter_analyses'].keys())[0]
        sample_analysis = report['copywriter_analyses'][sample_writer]
        
        print(f"\nğŸ“ Sample Analysis - {sample_writer}:")
        print(f"  Total Works: {sample_analysis['total_works']}")
        print(f"  Avg Copy Length: {sample_analysis['avg_copy_length']:.1f} characters")
        print(f"  Readability Score: {sample_analysis['readability_score']:.1f}")
        print(f"  Top Keywords: {[kw[0] for kw in sample_analysis['top_keywords'][:3]]}")
        print(f"  Common Themes: {sample_analysis['common_themes']}")
        print(f"  Active Period: {sample_analysis['active_period'][0]}-{sample_analysis['active_period'][1]}")
    
    # çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    filename = analyzer.export_analysis_results(report)
    
    print(f"\nâœ… Style analysis completed!")
    print(f"ğŸ“ Detailed report saved to: {filename}")
    
    return report

if __name__ == "__main__":
    demo_report = run_style_analysis_demo()